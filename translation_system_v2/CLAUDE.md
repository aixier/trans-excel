# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## âš ï¸ æ ¸å¿ƒæ¶æ„ç†å¿µï¼ˆå¿…è¯»ï¼‰

**åœ¨è¿›è¡Œä»»ä½•å¼€å‘ä¹‹å‰ï¼Œè¯·å…ˆé˜…è¯»ï¼š** `.claude/ARCHITECTURE_PRINCIPLES.md`

### ä¸‰å¤§æ ¸å¿ƒåŸåˆ™

#### 1. æ•°æ®çŠ¶æ€çš„è¿ç»­æ€§
**åŸå§‹æ•°æ® = ç»“æœæ•°æ® = æ•°æ®çŠ¶æ€**

ä¸å­˜åœ¨"åŸå§‹"å’Œ"ç»“æœ"çš„æœ¬è´¨åŒºåˆ«ï¼Œæ‰€æœ‰æ•°æ®éƒ½æ˜¯æŸä¸ªæ—¶åˆ»çš„çŠ¶æ€å¿«ç…§ï¼š
- ExcelåŸå§‹æ–‡ä»¶ = æ•°æ®çŠ¶æ€0
- Excelç¿»è¯‘å = æ•°æ®çŠ¶æ€1
- Excelå¤§å†™è½¬æ¢å = æ•°æ®çŠ¶æ€2
- ä»»ä½•çŠ¶æ€éƒ½å¯ä»¥ä½œä¸ºä¸‹ä¸€ä¸ªè½¬æ¢çš„è¾“å…¥

#### 2. ä»»åŠ¡æ‹†åˆ†è¡¨æ˜¯å”¯ä¸€çš„ä¸­é—´æ•°æ®
ä»»åŠ¡è¡¨æè¿°"å¦‚ä½•ä»çŠ¶æ€Nå˜æˆçŠ¶æ€N+1"ï¼Œå®ƒä¸æ˜¯æ•°æ®æœ¬èº«ï¼Œè€Œæ˜¯çŠ¶æ€è½¬æ¢çš„æŒ‡ä»¤é›†ã€‚

#### 3. ç»Ÿä¸€çš„è½¬æ¢æµç¨‹
```
æ•°æ®çŠ¶æ€N â†’ [æ‹†åˆ†å™¨] â†’ ä»»åŠ¡è¡¨ â†’ [è½¬æ¢å™¨] â†’ æ•°æ®çŠ¶æ€N+1
                                               â†“
                                          å¯ç»§ç»­æµè½¬
```

è¿™ä¸ªæµç¨‹å¯ä»¥æ— é™å¾ªç¯ï¼Œæ¯ä¸ªé˜¶æ®µéƒ½éµå¾ªç›¸åŒçš„æ¨¡å¼ã€‚

**è¯¦ç»†è¯´æ˜è¯·æŸ¥çœ‹ï¼š**
- `.claude/ARCHITECTURE_PRINCIPLES.md` - å®Œæ•´çš„æ¶æ„åŸåˆ™
- `.claude/PIPELINE_REFACTOR_PLAN.md` - æœ€æ–°çš„Pipelineé‡æ„æ–¹æ¡ˆï¼ˆæ¨èé˜…è¯»ï¼‰
- `backend_v2/SIMPLIFIED_ARCHITECTURE.md` - ç®€åŒ–æ¶æ„è®¾è®¡æ–‡æ¡£
- `backend_v2/PIPELINE_ARCHITECTURE.md` - ç®¡é“å¼æ¶æ„è®¾è®¡

---

## Overview

This is a Translation System V2 - an Excel-based translation management system that processes game localization files using LLMs (Large Language Models). The system analyzes Excel files containing multilingual text, splits them into translation tasks, executes translations via LLM APIs, and exports the results back to Excel format.

## Architecture

### æ–°æ¶æ„æ¨¡å‹ï¼ˆåŸºäºæ•°æ®æµç†å¿µï¼‰

ç³»ç»Ÿé‡‡ç”¨**æ•°æ®çŠ¶æ€æµè½¬**æ¨¡å¼ï¼Œæ‰€æœ‰æ“ä½œéƒ½éµå¾ªç»Ÿä¸€çš„è½¬æ¢æµç¨‹ï¼š

```
æ•°æ®çŠ¶æ€ â†’ [æ‹†åˆ†å™¨] â†’ ä»»åŠ¡è¡¨ â†’ [è½¬æ¢å™¨] â†’ æ–°æ•°æ®çŠ¶æ€ â†’ ä¸‹ä¸€ä¸ªé˜¶æ®µ...
```

**ç¤ºä¾‹æµç¨‹**ï¼ˆCAPSç¿»è¯‘ï¼‰ï¼š
```
çŠ¶æ€0(åŸå§‹Excel)
    â†“ [æ‹†åˆ†] è§„åˆ™: ç©ºå•å…ƒæ ¼ã€é»„è‰²å•å…ƒæ ¼
ä»»åŠ¡è¡¨1(ç¿»è¯‘ä»»åŠ¡)
    â†“ [è½¬æ¢] LLMç¿»è¯‘å¤„ç†å™¨
çŠ¶æ€1(ç¿»è¯‘åExcel)
    â†“ [æ‹†åˆ†] è§„åˆ™: CAPS sheet
ä»»åŠ¡è¡¨2(å¤§å†™ä»»åŠ¡)
    â†“ [è½¬æ¢] å¤§å†™å¤„ç†å™¨(ä¾èµ–ä»»åŠ¡è¡¨1)
çŠ¶æ€2(æœ€ç»ˆExcel)
```

### Core Components

- **Backend (FastAPI)**: Located in `backend_v2/`, handles all business logic, LLM integrations, and task processing
- **Frontend (Vanilla JS)**: Located in `frontend_v2/`, single-page application with hash routing, no framework dependencies
- **Memory-Only Mode**: All data stored in memory, no database persistence, sessions timeout after 8 hours
- **Task DataFrame**: ä»»åŠ¡æ‹†åˆ†è¡¨ - æè¿°çŠ¶æ€è½¬æ¢çš„å”¯ä¸€ä¸­é—´æ•°æ®
- **Data State**: Excelæ•°æ®çŠ¶æ€ - å¯ä»¥æ— é™æµè½¬çš„æ•°æ®å¿«ç…§
- **PipelineSession**: ç®¡é“ä¼šè¯ - æ¯ä¸ªSessionç®¡ç†ä¸€æ¬¡è½¬æ¢ï¼ˆä¸€ä¸ªè¾“å…¥çŠ¶æ€â†’ä¸€ä¸ªè¾“å‡ºçŠ¶æ€ï¼‰
- **Session Chaining**: ä¼šè¯é“¾æ¥ - é€šè¿‡parent_session_idå®ç°å¤šé˜¶æ®µPipeline

### ç³»ç»Ÿçš„ä¸‰ç§æ•°æ®æ ¼å¼ â­

ç³»ç»Ÿåªæœ‰ä¸‰ç§æ•°æ®æ ¼å¼ï¼Œå®ƒä»¬å¯¹åº”æ¶æ„åŸåˆ™ä¸­çš„æ ¸å¿ƒæ¦‚å¿µï¼š

#### 1. Excelæ–‡ä»¶æ ¼å¼ï¼ˆ.xlsxï¼‰
**è§’è‰²**ï¼šç”¨æˆ·å¯è§çš„å¤–éƒ¨æ ¼å¼
```
ç”¨æˆ·è§†è§’ï¼šinput.xlsx â†’ ç³»ç»Ÿå¤„ç† â†’ output.xlsx
```
- **ç”¨é€”**ï¼šå¤–éƒ¨è¾¹ç•Œçš„æ•°æ®äº¤æ¢æ ¼å¼
- **å‡ºç°ä½ç½®**ï¼šç”¨æˆ·ä¸Šä¼ ã€ç”¨æˆ·ä¸‹è½½
- **ç‰¹ç‚¹**ï¼šäººç±»å¯è¯»ã€å¯ç¼–è¾‘ã€æ ‡å‡†Excelæ ¼å¼

#### 2. ExcelDataFrameï¼ˆæ•°æ®çŠ¶æ€ï¼‰â­â­â­
**è§’è‰²**ï¼šå†…éƒ¨æ•°æ®çŠ¶æ€è¡¨ç¤ºï¼ˆå¯¹åº”æ¶æ„åŸåˆ™ä¸­çš„"æ•°æ®çŠ¶æ€N"ï¼‰

**æ ¸å¿ƒç†å¿µï¼šDataFrame Pipeline** ğŸ¯

æ•´ä¸ªç³»ç»Ÿå°±æ˜¯ä¸€ä¸ª **DataFrame çš„ Pipeline**ï¼æ‰€æœ‰æ•°æ®çŠ¶æ€éƒ½æ˜¯**ç›¸åŒæ ¼å¼çš„ DataFrame**ï¼š

```python
# models/excel_dataframe.py
@dataclass
class ExcelDataFrame:
    sheets: Dict[str, pd.DataFrame]  # DataFrameåŒ…å«æ‰€æœ‰ä¿¡æ¯
    filename: str
    excel_id: str

# DataFrame åˆ—ç»“æ„ï¼ˆç»Ÿä¸€æ ¼å¼ï¼‰ï¼š
# - æ•°æ®åˆ—ï¼škey, CH, EN, TH, PT, VN
# - é¢œè‰²åˆ—ï¼šcolor_CH, color_EN, color_TH, color_PT, color_VN
# - æ³¨é‡Šåˆ—ï¼šcomment_CH, comment_EN, comment_TH, comment_PT, comment_VN
```

**DataFrame ç¤ºä¾‹**ï¼š
```
key              CH         color_CH   comment_CH        EN           color_EN  comment_EN
PET_SKILL_1      å¼ºåŒ–å® ç‰©... #FFFFFF00  æ ¼å¼å ä½ç¬¦æœ‰è¯¯    Enhance...   #FFFFFF00  åŸæ–‡ï¼š...
ELEMENT_BOX_2    åˆé˜¶å¢¨æ°´... None       None             example1     #FFFFFF00  None
```

**ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡ï¼Ÿ**
- âœ… **æ ¼å¼ä¸€è‡´æ€§**ï¼šstate_0, state_1, state_2 ... éƒ½æ˜¯ç›¸åŒæ ¼å¼çš„ DataFrame
- âœ… **å¯çº§è”æ€§**ï¼šä»»ä½•çŠ¶æ€éƒ½å¯ä»¥ä½œä¸ºä¸‹ä¸€ä¸ªè½¬æ¢çš„è¾“å…¥
- âœ… **å•ä¸€æ•°æ®æº**ï¼šæ‰€æœ‰ä¿¡æ¯åœ¨ DataFrame ä¸­ï¼Œä¸éœ€è¦å•ç‹¬çš„å­—å…¸
- âœ… **ç®€åŒ–å¤„ç†**ï¼šå¤„ç†å™¨è¾“å…¥/è¾“å‡ºéƒ½æ˜¯ DataFrameï¼Œä¿æŒæ ¼å¼ä¸€è‡´

**æ—§è®¾è®¡ï¼ˆå·²åºŸå¼ƒï¼‰**ï¼š
```python
# âŒ æ—§è®¾è®¡ï¼šåˆ†ç¦»å­˜å‚¨
class ExcelDataFrame:
    sheets: Dict[str, pd.DataFrame]  # åªæœ‰æ•°æ®åˆ—
    color_map: Dict  # å•ç‹¬çš„é¢œè‰²å­—å…¸
    comment_map: Dict  # å•ç‹¬çš„æ³¨é‡Šå­—å…¸
```
é—®é¢˜ï¼šæ ¼å¼ä¸ä¸€è‡´ï¼Œæ— æ³•å®ç° DataFrame Pipeline

- **ç”¨é€”**ï¼šè¡¨ç¤ºæŸä¸ªæ—¶åˆ»çš„å®Œæ•´æ•°æ®å¿«ç…§
- **å‡ºç°ä½ç½®**ï¼š
  - âœ… Splitçš„**è¾“å…¥**ï¼ˆsession.input_stateï¼‰
  - âœ… Executeçš„**è¾“å‡º**ï¼ˆsession.output_stateï¼‰
  - âœ… Sessionä¹‹é—´çš„ç»§æ‰¿ï¼ˆparentçš„output_state â†’ childçš„input_stateï¼‰
- **ç‰¹ç‚¹**ï¼šå†…å­˜å¯¹è±¡ã€100%ä¿ç•™æ‰€æœ‰æ•°æ®å’Œå…ƒæ•°æ®ã€é›¶æ‹·è´ä¼ é€’ã€æ ¼å¼ä¸€è‡´å¯çº§è”

#### 3. TaskDataFrameï¼ˆä»»åŠ¡è¡¨ï¼‰
**è§’è‰²**ï¼šçŠ¶æ€è½¬æ¢çš„æŒ‡ä»¤é›†ï¼ˆå¯¹åº”æ¶æ„åŸåˆ™ä¸­çš„"ä»»åŠ¡æ‹†åˆ†è¡¨"ï¼‰
```python
# models/task_dataframe.py
class TaskDataFrameManager:
    df: DataFrame with columns:
        - task_id, sheet_name, row_idx, col_idx
        - source_text, target_lang
        - task_type, status, result
        # ... ä»»åŠ¡æ‰§è¡Œä¿¡æ¯
```
- **ç”¨é€”**ï¼šæè¿°"å¦‚ä½•ä»çŠ¶æ€Nå˜æˆçŠ¶æ€N+1"
- **å‡ºç°ä½ç½®**ï¼š
  - âœ… Splitçš„**è¾“å‡º**ï¼ˆsession.tasksï¼‰
  - âœ… Executeçš„**è¾“å…¥**ï¼ˆtasks + input_stateä¸€èµ·ï¼‰
- **ç‰¹ç‚¹**ï¼šä¸æ˜¯æ•°æ®æœ¬èº«ï¼Œè€Œæ˜¯å¯¹æ•°æ®çš„æ“ä½œæè¿°

#### æ•°æ®æµè½¬è§„åˆ™

**æ ¼å¼è½¬æ¢è¾¹ç•Œï¼ˆå”¯ä¸€çš„I/Oç‚¹ï¼‰**ï¼š
```
ä¸Šä¼ ï¼š.xlsxæ–‡ä»¶ â†’ [è§£æ] â†’ ExcelDataFrame
ä¸‹è½½ï¼šExcelDataFrame â†’ [åºåˆ—åŒ–] â†’ .xlsxæ–‡ä»¶
```

**ç³»ç»Ÿå†…éƒ¨æµè½¬ï¼ˆæ— æ ¼å¼è½¬æ¢ï¼‰**ï¼š
```
Split:   ExcelDataFrame â†’ TaskDataFrame
Execute: ExcelDataFrame + TaskDataFrame â†’ ExcelDataFrame
ç»§æ‰¿ï¼š    parent.output_state (ExcelDataFrame) â†’ child.input_state (ExcelDataFrame)
```

#### å®Œæ•´Pipelineç¤ºä¾‹

**é˜¶æ®µ1ï¼ˆç¿»è¯‘ï¼‰ï¼š**
```
input.xlsx                    # æ ¼å¼1ï¼šExcelæ–‡ä»¶
    â†“ ä¸Šä¼ è§£æ
ExcelDataFrame (state_0)      # æ ¼å¼2ï¼šæ•°æ®çŠ¶æ€
    â†“ Split
TaskDataFrame (tasks_1)       # æ ¼å¼3ï¼šä»»åŠ¡è¡¨
    â†“ Execute (éœ€è¦state_0 + tasks_1)
ExcelDataFrame (state_1)      # æ ¼å¼2ï¼šæ•°æ®çŠ¶æ€
```

**é˜¶æ®µ2ï¼ˆCAPSï¼‰- å†…å­˜ç»§æ‰¿ï¼š**
```
ExcelDataFrame (state_1)      # æ ¼å¼2ï¼šæ•°æ®çŠ¶æ€ï¼ˆä»ä¸Šä¸€é˜¶æ®µç»§æ‰¿ï¼Œæ— éœ€æ–‡ä»¶è½¬æ¢ï¼‰
    â†“ Split
TaskDataFrame (tasks_2)       # æ ¼å¼3ï¼šä»»åŠ¡è¡¨
    â†“ Execute (éœ€è¦state_1 + tasks_2)
ExcelDataFrame (state_2)      # æ ¼å¼2ï¼šæ•°æ®çŠ¶æ€
    â†“ ä¸‹è½½åºåˆ—åŒ–
output.xlsx                   # æ ¼å¼1ï¼šExcelæ–‡ä»¶
```

**å…³é”®ç‚¹**ï¼š
- âœ… ä¸Šä¼ æ–‡ä»¶å’Œä»çˆ¶Sessionç»§æ‰¿éƒ½å¾—åˆ°**ç›¸åŒæ ¼å¼**ï¼ˆExcelDataFrameï¼‰
- âœ… Splitè¾“å…¥ExcelDataFrameï¼Œè¾“å‡ºTaskDataFrame
- âœ… Executeè¾“å…¥ExcelDataFrame + TaskDataFrameï¼Œè¾“å‡ºExcelDataFrame
- âœ… ç³»ç»Ÿå†…éƒ¨æµè½¬é›¶æ‹·è´ï¼Œåªæœ‰å¤–éƒ¨è¾¹ç•Œéœ€è¦æ ¼å¼è½¬æ¢

### Key Design Patterns

1. **Data State Flow**: æ•°æ®çŠ¶æ€è¿ç»­æµè½¬ï¼Œä»»ä½•è¾“å‡ºéƒ½å¯ä½œä¸ºä¸‹ä¸€ä¸ªè¾“å…¥
2. **Session-per-Transformation**: æ¯ä¸ªSessionç®¡ç†ä¸€æ¬¡è½¬æ¢ï¼Œä¸æ˜¯å¤šä¸ªçŠ¶æ€
3. **Parent-Child Session Chaining**: Sessioné€šè¿‡parent_session_idé“¾æ¥ï¼Œå®ç°å¤šé˜¶æ®µPipeline
4. **Configuration-Driven Processing**: Ruleså’ŒProcessorsé€šè¿‡YAMLé…ç½®ï¼Œç”±Factoryåˆ›å»º
5. **Task-Driven Transformation**: é€šè¿‡ä»»åŠ¡è¡¨é©±åŠ¨æ•°æ®è½¬æ¢ï¼Œè€Œéç›´æ¥ä¿®æ”¹
6. **Rule-Based Splitting**: æ‹†åˆ†å™¨ä½¿ç”¨å¯é…ç½®è§„åˆ™ï¼Œè€Œéç¡¬ç¼–ç é€»è¾‘
7. **Modular Processors**: è½¬æ¢å™¨åªå…³å¿ƒä»»åŠ¡æ‰§è¡Œï¼Œä¸å…³å¿ƒæ•°æ®æ¥æº
8. **Worker Pool Pattern**: Concurrent execution using configurable worker pools (default 10 workers)
9. **Batch Processing**: Tasks grouped by character count (max 50,000 chars per batch) for efficient LLM calls
10. **WebSocket Real-time Updates**: Progress monitoring via WebSocket connections

## å¼€å‘è§„èŒƒï¼ˆå¿…é¡»éµå®ˆï¼‰

### âœ… æ­£ç¡®çš„å¼€å‘æ–¹å¼

1. **åˆ†ç¦»æ‹†åˆ†å’Œè½¬æ¢**
   ```python
   # âœ… æ­£ç¡®ï¼šåˆ†ä¸¤ä¸ªé˜¶æ®µ
   tasks = splitter.split(data_state, rules)  # æ‹†åˆ†
   new_state = transformer.execute(data_state, tasks)  # è½¬æ¢

   # âŒ é”™è¯¯ï¼šåœ¨æ‹†åˆ†æ—¶æ‰§è¡Œè½¬æ¢
   tasks = splitter.split_and_translate(data_state)
   ```

2. **çŠ¶æ€ç‹¬ç«‹æ€§**
   ```python
   # âœ… æ­£ç¡®ï¼šæ¯ä¸ªçŠ¶æ€å¯ä»¥ç‹¬ç«‹ä½¿ç”¨
   state_1 = load_excel("translated.xlsx")
   tasks = splitter.split(state_1, rules=[CapsRule])

   # âŒ é”™è¯¯ï¼šå‡è®¾ä¸€å®šæ˜¯ä»åŸå§‹æ–‡ä»¶å¼€å§‹
   if not is_original_file(data_state):
       raise Error("Must start from original")
   ```

3. **è½¬æ¢å™¨ä¾èµ–ç®¡ç†**
   ```python
   # âœ… æ­£ç¡®ï¼šé€šè¿‡contextä¼ é€’ä¾èµ–
   state_2 = transformer.execute(
       state_1,
       tasks_2,
       context={'previous_tasks': tasks_1}
   )

   # âŒ é”™è¯¯ï¼šè½¬æ¢å™¨å†…éƒ¨æŸ¥æ‰¾ä¾èµ–
   state_2 = transformer.execute_with_lookup(state_1, tasks_2)
   ```

### âŒ ç¦æ­¢çš„åšæ³•

1. **ä¸è¦åœ¨æ‹†åˆ†é˜¶æ®µåˆ›å»ºä¾èµ–å…¶ä»–ä»»åŠ¡çš„ä»»åŠ¡**
   ```python
   # âŒ CAPSä»»åŠ¡ä¸åº”è¯¥åœ¨ç¿»è¯‘å‰åˆ›å»º
   tasks = splitter.split(original_excel, rules=[
       NormalTranslation,
       CapsUppercase  # æ­¤æ—¶ç¿»è¯‘è¿˜æ²¡æ‰§è¡Œï¼
   ])
   ```

2. **ä¸è¦åœ¨è½¬æ¢å™¨ä¸­æ‰§è¡Œæ‹†åˆ†é€»è¾‘**
   ```python
   # âŒ LLMè½¬æ¢å™¨ä¸åº”è¯¥å¤„ç†CAPSä»»åŠ¡
   def translate(task):
       if task['type'] == 'caps':
           # ä¸è¦åœ¨è¿™é‡Œåšå¤§å†™è½¬æ¢ï¼
           return task['source'].upper()
   ```

3. **ä¸è¦æ··æ·†æ•°æ®çŠ¶æ€å’Œä»»åŠ¡è¡¨**
   ```python
   # âŒ ä»»åŠ¡è¡¨ä¸åº”è¯¥å­˜å‚¨å®Œæ•´æ•°æ®
   task['full_excel_data'] = excel_df

   # âœ… ä»»åŠ¡è¡¨åªå­˜å‚¨ä½ç½®å’Œæ“ä½œ
   task['sheet_name'] = 'Sheet1'
   task['row_idx'] = 0
   ```

### æ·»åŠ æ–°åŠŸèƒ½æ—¶çš„æ­¥éª¤

1. **ç¡®å®šæ˜¯æ‹†åˆ†è§„åˆ™è¿˜æ˜¯è½¬æ¢å¤„ç†å™¨**
2. **å®ç°ç‹¬ç«‹çš„ç±»ï¼ˆä¸ä¾èµ–ç°æœ‰é€»è¾‘ï¼‰**
3. **é€šè¿‡é…ç½®æˆ–ç¼–æ’å™¨ç»„è£…åˆ°æµç¨‹**
4. **æ›´æ–°æ¶æ„æ–‡æ¡£è¯´æ˜æ–°å¢åŠŸèƒ½**

**è¯¦ç»†è§„èŒƒè¯·æŸ¥çœ‹ï¼š** `.claude/ARCHITECTURE_PRINCIPLES.md`

## Development Commands

### Backend Setup and Running

âš ï¸ **IMPORTANT**: Always use `python3` command, NOT `python`, to avoid compatibility issues.

```bash
# Navigate to backend
cd backend_v2

# Install dependencies
pip3 install -r requirements.txt

# Run the backend server (MUST use python3)
python3 main.py
# Server runs on http://localhost:8013 by default

# Run specific test files
python3 test_api_flow.py
python3 test_batch_allocator_max_chars.py
python3 test_translation_flow.py

# Run unit tests
python3 -m pytest tests/
```

### Frontend Setup

```bash
# Navigate to frontend
cd frontend_v2

# Serve with Python (no build needed - pure HTML/JS/CSS)
python -m http.server 8080

# Or use Node.js
npx http-server -p 8080

# Access at http://localhost:8080
```

### Docker Deployment (Optional)

```bash
# Build and run with Docker
docker build -t translation-system .
docker run -p 8013:8013 translation-system
```

## Configuration

### Backend Configuration

Main config files:
- `backend_v2/config/config.yaml` - ç³»ç»Ÿé…ç½®
- `backend_v2/config/rules.yaml` - æ‹†åˆ†è§„åˆ™é…ç½®ï¼ˆæ–°å¢ï¼‰
- `backend_v2/config/processors.yaml` - å¤„ç†å™¨é…ç½®ï¼ˆæ–°å¢ï¼‰

Key configuration parameters in `config.yaml`:
- `task_execution.batch_control.max_chars_per_batch`: Max characters per LLM batch (default: 1000)
- `task_execution.batch_control.max_concurrent_workers`: Max concurrent workers (default: 10)
- `llm.providers`: Configure different LLM providers (OpenAI, Qwen, etc.)
- `llm.default_provider`: Set default LLM provider (default: qwen-plus)

### Rules Configuration (`config/rules.yaml`)

å®šä¹‰æ‹†åˆ†è§„åˆ™å’Œè§„åˆ™é›†ï¼š
```yaml
rules:
  empty:
    class: services.splitter.rules.empty_cell.EmptyCellRule
    priority: 5
    enabled: true

  caps:
    class: services.splitter.rules.caps_sheet.CapsSheetRule
    priority: 3
    enabled: true
    requires_translation_first: true  # CAPSéœ€è¦ç¿»è¯‘åæ‰èƒ½æ‰§è¡Œ

rule_sets:
  translation:  # ç¿»è¯‘è§„åˆ™é›†
    - empty
    - yellow
    - blue

  caps_only:    # CAPSè§„åˆ™é›†
    - caps
```

### Processors Configuration (`config/processors.yaml`)

å®šä¹‰å¤„ç†å™¨å’Œå¤„ç†å™¨é›†ï¼š
```yaml
processors:
  llm_qwen:
    class: services.llm.qwen_provider.QwenProvider
    type: llm_translation
    enabled: true

  uppercase:
    class: services.processors.uppercase_processor.UppercaseProcessor
    type: text_transform
    enabled: true
    requires_llm: false

processor_sets:
  default_translation:
    processor: llm_qwen
    max_workers: 10

  caps_transform:
    processor: uppercase
    max_workers: 20
```

### LLM Providers

Currently supported providers in `backend_v2/services/llm/`:
- **OpenAI** (`openai_provider.py`): GPT-4, GPT-3.5
- **Qwen** (`qwen_provider.py`): Alibaba Cloud's Qwen models
- Base class for custom providers: `base_provider.py`

To add a new LLM provider, extend `BaseLLMProvider` and register in `llm_factory.py`.

## Key APIs

### Task Management (æ–°æ¶æ„)

**Split APIï¼ˆåˆå¹¶äº†Analyzeï¼‰**
```
POST /api/tasks/split
Body: {
  "file": <file_upload>,         // ä¸Šä¼ æ–°æ–‡ä»¶
  "source_lang": "CH",
  "target_langs": ["EN", "JP"],
  "rule_set": "translation"       // ä½¿ç”¨å“ªä¸ªè§„åˆ™é›†
}
æˆ–
Body: {
  "parent_session_id": "xxx",     // ä»çˆ¶Sessionç»§æ‰¿æ•°æ®
  "rule_set": "caps_only"         // ä½¿ç”¨ä¸åŒçš„è§„åˆ™é›†
}

Response: {
  "session_id": "new-session-id",
  "parent_session_id": "xxx",     // å¦‚æœæœ‰
  "tasks_count": 100,
  "stage": "SPLIT_COMPLETED"
}
```

**Execute APIï¼ˆæ–°å¢processorå‚æ•°ï¼‰**
```
POST /api/execute/start
Body: {
  "session_id": "xxx",
  "processor": "llm_qwen",        // æŒ‡å®šå¤„ç†å™¨
  "max_workers": 10
}
æˆ–
Body: {
  "session_id": "xxx",
  "processor": "uppercase",       // CAPSå¤„ç†å™¨
  "max_workers": 20
}
```

**Status APIs**
- `GET /api/tasks/status/{session_id}` - Get task split status
- `GET /api/execute/status/{session_id}` - Get execution status
- `GET /api/tasks/export/{session_id}` - Export tasks as Excel

### Results & Download
- `GET /api/download/{session_id}` - Download translated Excel
- `GET /api/download/{session_id}/info` - Get download info
- `GET /api/download/{session_id}/summary` - Get translation summary

### WebSocket
- `WS /api/websocket/progress/{session_id}` - Real-time progress updates

## Task Processing Flow

### æ–°æ¶æ„ï¼šMulti-Stage Pipeline

æ¯ä¸ªé˜¶æ®µéƒ½æ˜¯ç‹¬ç«‹çš„Sessionï¼Œé€šè¿‡parent_session_idé“¾æ¥ï¼š

**é˜¶æ®µ1ï¼šç¿»è¯‘ (Translation Stage)**
1. **Split**: ä¸Šä¼ Excelï¼Œä½¿ç”¨translationè§„åˆ™é›†æ‹†åˆ†ä»»åŠ¡
   - `POST /api/tasks/split` with file + rule_set="translation"
   - åˆ›å»ºSession 1ï¼Œç”Ÿæˆç¿»è¯‘ä»»åŠ¡
2. **Execute**: ä½¿ç”¨LLMå¤„ç†å™¨æ‰§è¡Œç¿»è¯‘
   - `POST /api/execute/start` with processor="llm_qwen"
   - å¹¶å‘å¤„ç†ï¼Œå®æ—¶ç›‘æ§
3. **Download**: ä¸‹è½½ç¿»è¯‘åçš„Excelï¼ˆæ•°æ®çŠ¶æ€1ï¼‰
   - `GET /api/download/{session_id}`

**é˜¶æ®µ2ï¼šCAPSè½¬æ¢ (CAPS Stage) - å¯é€‰**
1. **Split**: ä½¿ç”¨Session 1çš„è¾“å‡ºï¼Œæ‹†åˆ†CAPSä»»åŠ¡
   - `POST /api/tasks/split` with parent_session_id=session1 + rule_set="caps_only"
   - åˆ›å»ºSession 2ï¼Œç”ŸæˆCAPSä»»åŠ¡ï¼ˆæ­¤æ—¶source_textå·²æœ‰ç¿»è¯‘å†…å®¹ï¼‰
2. **Execute**: ä½¿ç”¨Uppercaseå¤„ç†å™¨æ‰§è¡ŒCAPS
   - `POST /api/execute/start` with processor="uppercase"
   - å¿«é€Ÿå¤„ç†ï¼ˆç®€å•è½¬æ¢ï¼‰
3. **Download**: ä¸‹è½½æœ€ç»ˆExcelï¼ˆæ•°æ®çŠ¶æ€2ï¼‰
   - `GET /api/download/{session_id}`

### å•ä¸ªSessionå†…çš„å¤„ç†æµç¨‹

1. **Split**: æ ¹æ®è§„åˆ™æ‹†åˆ†ä»»åŠ¡
2. **Batch**: Tasks grouped into batches by character count (dynamic sizing)
3. **Execute**: Batches processed concurrently by worker pool
4. **Monitor**: Real-time progress via WebSocket
5. **Complete**: Sessionè¿›å…¥COMPLETEDçŠ¶æ€ï¼Œå¯ä¸‹è½½æˆ–ä½œä¸ºä¸‹ä¸€é˜¶æ®µè¾“å…¥

### Task Types (Based on Cell Colors)

- **Normal (white/no color)**: Standard translation tasks
- **Yellow**: Re-translation tasks (high priority)
- **Blue**: Text simplification tasks (medium priority)
- **CAPS**: Uppercase conversion tasks (requires translation first)

## Important Architecture Details

### Session Management (æ–°æ¶æ„)

The system uses `PipelineSessionManager` (`backend_v2/utils/pipeline_session_manager.py`) that manages session chains:

**æ ¸å¿ƒå˜åŒ–ï¼š**
- **ä¸€ä¸ªSession = ä¸€æ¬¡è½¬æ¢**ï¼ˆä¸å†ç®¡ç†å¤šä¸ªçŠ¶æ€ï¼‰
- **Parent-Childé“¾æ¥**ï¼šSessionsé€šè¿‡parent_session_idå…³è”
- **ç‹¬ç«‹å¯æµ‹è¯•**ï¼šæ¯ä¸ªSessionéƒ½å¯ä»¥ç‹¬ç«‹éªŒè¯
- **é…ç½®é©±åŠ¨**ï¼šRuleså’ŒProcessorsé€šè¿‡YAMLé…ç½®

**Sessionç»“æ„** (`models/pipeline_session.py`):
```python
@dataclass
class PipelineSession:
    session_id: str
    stage: TransformationStage  # CREATED/SPLIT_COMPLETED/EXECUTION_COMPLETED

    # Input
    input_state: ExcelDataFrame
    input_source: str  # 'file' or 'parent_session'
    parent_session_id: Optional[str]

    # Configuration
    rules: List[str]  # è§„åˆ™åç§°åˆ—è¡¨
    processor: Optional[str]  # å¤„ç†å™¨åç§°

    # Output
    tasks: TaskDataFrameManager
    output_state: ExcelDataFrame

    # Chaining
    child_session_ids: List[str]
```

**Sessionç”Ÿå‘½å‘¨æœŸï¼š**
1. CREATED - Sessionåˆ›å»ºï¼Œinput_stateå·²åŠ è½½
2. SPLIT_COMPLETED - ä»»åŠ¡æ‹†åˆ†å®Œæˆï¼Œtaskså·²ç”Ÿæˆ
3. EXECUTION_COMPLETED - ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼Œoutput_stateå·²ç”Ÿæˆ
4. ï¼ˆå¯é€‰ï¼‰ä½œä¸ºparent_sessionè¢«ä¸‹ä¸€ä¸ªSessionä½¿ç”¨

**è€æ¶æ„é—®é¢˜ï¼š**
- âŒ ä¸€ä¸ªSessionç®¡ç†å¤šä¸ªçŠ¶æ€ï¼ˆstate_0, state_1, state_2ï¼‰
- âŒ é«˜è€¦åˆï¼Œ18+æ¨¡å—ä¾èµ–session_manager
- âŒ éš¾ä»¥æµ‹è¯•å•ä¸ªé˜¶æ®µ
- âŒ CAPSä»»åŠ¡åœ¨ç¿»è¯‘å‰åˆ›å»ºï¼Œsource_textä¸ºç©º

**æ–°æ¶æ„ä¼˜åŠ¿ï¼š**
- âœ… æ¯ä¸ªSessionèŒè´£å•ä¸€
- âœ… é€šè¿‡parent_session_idæ˜¾å¼é“¾æ¥
- âœ… æ¯ä¸ªé˜¶æ®µç‹¬ç«‹æµ‹è¯•
- âœ… CAPSä»»åŠ¡åœ¨ç¿»è¯‘ååˆ›å»ºï¼Œsource_textæœ‰å€¼

### Task DataFrame Structure

Main columns in the task DataFrame (`backend_v2/models/task_dataframe.py`):
- `task_id`: Unique identifier
- `batch_id`: Batch grouping for LLM calls
- `source_text`, `target_lang`: Translation input/output
- `status`: pending/processing/completed/failed
- `result`: Translation result
- `row_idx`, `col_idx`: Excel position
- `task_type`: normal/yellow/blue

### Worker Pool Architecture

**å¤šç”¨æˆ·å¹¶å‘æ¶æ„** (`backend_v2/services/executor/`):
- **WorkerPoolManager** (`worker_pool_manager.py`): ç®¡ç†å¤šä¸ªsessionçš„worker pool
  - ä¸ºæ¯ä¸ªsessionåˆ›å»ºç‹¬ç«‹çš„WorkerPoolå®ä¾‹
  - æä¾›sessionçº§åˆ«çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†
  - æ”¯æŒè‡ªåŠ¨æ¸…ç†å·²å®Œæˆçš„pool
- **WorkerPool** (`worker_pool.py`): å•ä¸ªsessionçš„å¹¶å‘æ‰§è¡Œå™¨
  - æ¯ä¸ªå®ä¾‹ç»‘å®šä¸€ä¸ªsession_id
  - Configurable concurrent workers (1-50 per session)
  - Automatic retry with exponential backoff
  - Rate limiting for API calls
  - Dynamic batch size adjustment
- **å¤šç”¨æˆ·åœºæ™¯**:
  - ç”¨æˆ·Aæ‰§è¡Œsession_1ç¿»è¯‘ï¼Œç”¨æˆ·BåŒæ—¶æ‰§è¡Œsession_2çš„CAPSï¼Œäº’ä¸å¹²æ‰°
  - æ¯ä¸ªsessionå¯ç‹¬ç«‹æ§åˆ¶ï¼ˆstart/stop/pause/resumeï¼‰
  - APIé€šè¿‡session_idè·¯ç”±åˆ°å¯¹åº”çš„WorkerPoolå®ä¾‹

## Testing

### Backend Testing

```bash
# Run all unit tests
cd backend_v2
python -m pytest tests/ -v

# Run specific test scenarios
python test_api_flow.py  # Test complete API flow
python test_batch_allocator_max_chars.py  # Test batch allocation
python test_translation_flow.py  # Test translation pipeline
python test_yellow_en_reference.py  # Test yellow cell logic

# Test with real Excel files
python test_real_excel.py  # Requires sample Excel in tests/test_data/
```

### Frontend Testing

The frontend includes test pages in `frontend_v2/test_pages/`:
- Open individual HTML files to test specific features
- Check browser console for debug output
- Verify WebSocket connections and API calls

## Common Development Tasks

### Adding a New Rule (æ‹†åˆ†è§„åˆ™)

1. Create rule class in `backend_v2/services/splitter/rules/`
   ```python
   class MyCustomRule:
       def match(self, cell_context) -> bool:
           # åˆ¤æ–­æ˜¯å¦åŒ¹é…
           return True/False

       def extract_task(self, cell_context) -> Dict:
           # æå–ä»»åŠ¡ä¿¡æ¯
           return {...}
   ```
2. Add configuration in `config/rules.yaml`
   ```yaml
   rules:
     my_custom:
       class: services.splitter.rules.my_custom.MyCustomRule
       priority: 5
       enabled: true
   ```
3. Add to rule set if needed
   ```yaml
   rule_sets:
     my_workflow:
       - my_custom
       - empty
   ```
4. Use via API: `POST /api/tasks/split` with `rule_set="my_workflow"`

### Adding a New Processor (å¤„ç†å™¨)

1. Create processor class in `backend_v2/services/processors/`
   ```python
   class MyProcessor:
       def process(self, task: Dict) -> str:
           # å¤„ç†ä»»åŠ¡ï¼Œè¿”å›ç»“æœ
           return result
   ```
2. Add configuration in `config/processors.yaml`
   ```yaml
   processors:
     my_processor:
       class: services.processors.my_processor.MyProcessor
       type: custom
       enabled: true
   ```
3. Use via API: `POST /api/execute/start` with `processor="my_processor"`

### Adding a New LLM Provider

1. Create provider class in `backend_v2/services/llm/`
2. Extend `BaseLLMProvider`
3. Implement `translate_batch()` method
4. Add to `config/processors.yaml`
   ```yaml
   processors:
     llm_my_provider:
       class: services.llm.my_provider.MyProvider
       type: llm_translation
       config:
         model: my-model
       enabled: true
   ```
5. Use via API: `POST /api/execute/start` with `processor="llm_my_provider"`

### Modifying Translation Prompts

Edit `backend_v2/services/llm/prompt_template.py`:
- Modify prompt templates for different task types
- Adjust context extraction logic
- Change output format requirements

### Adjusting Batch Processing

Edit `backend_v2/services/batch_allocator.py`:
- Modify `max_chars_per_batch` calculation
- Adjust batch grouping logic
- Change priority assignment

### Debugging Session Issues

Common session-related files:
- `backend_v2/utils/session_manager.py` - Session storage
- `backend_v2/models/session_state.py` - Session state model
- `backend_v2/api/session_api.py` - Session API endpoints

## Performance Tuning

### Key Parameters

In `config.yaml`:
- `max_chars_per_batch`: Increase for fewer API calls, decrease for faster response
- `max_concurrent_workers`: Increase for higher throughput, watch for rate limits
- `checkpoint_interval`: Frequency of optional file checkpoints (if enabled)

### Monitoring

Access performance metrics:
- `GET /api/monitor/status/{session_id}` - Task statistics
- `GET /api/monitor/pool` - Worker pool status
- WebSocket `/api/websocket/monitor` - Real-time metrics

## Migration Guide: Old to New Architecture

### æ ¸å¿ƒå˜åŒ–

**Old Architecture (å½“å‰):**
```python
# ä¸€ä¸ªSessionç®¡ç†æ‰€æœ‰çŠ¶æ€
POST /api/analyze/upload  # ä¸Šä¼ å¹¶åˆ†æ
POST /api/tasks/split     # æ‹†åˆ†ï¼ˆåŒ…å«CAPSä»»åŠ¡ï¼‰
POST /api/execute/start   # æ‰§è¡Œï¼ˆLLMè‡ªåŠ¨è¯†åˆ«ä»»åŠ¡ç±»å‹ï¼‰
GET  /api/download/{session_id}
```

**New Architecture (ç›®æ ‡):**
```python
# é˜¶æ®µ1ï¼šç¿»è¯‘
POST /api/tasks/split     # ä¸Šä¼ +åˆ†æ+æ‹†åˆ†ï¼ˆåˆå¹¶äº†analyzeï¼‰
  Body: {file: ..., rule_set: "translation"}
  â†’ session_id_1

POST /api/execute/start
  Body: {session_id: session_id_1, processor: "llm_qwen"}

GET /api/download/{session_id_1}  # ç¿»è¯‘åçš„Excel

# é˜¶æ®µ2ï¼šCAPSï¼ˆå¯é€‰ï¼‰
POST /api/tasks/split
  Body: {parent_session_id: session_id_1, rule_set: "caps_only"}
  â†’ session_id_2

POST /api/execute/start
  Body: {session_id: session_id_2, processor: "uppercase"}

GET /api/download/{session_id_2}  # æœ€ç»ˆExcel
```

### å…³é”®å·®å¼‚

| æ–¹é¢ | Old | New |
|------|-----|-----|
| SessionèŒè´£ | ç®¡ç†å¤šä¸ªçŠ¶æ€ | ç®¡ç†ä¸€æ¬¡è½¬æ¢ |
| CAPSä»»åŠ¡ | ç¿»è¯‘å‰åˆ›å»ºï¼ˆsource_textä¸ºç©ºï¼‰ | ç¿»è¯‘ååˆ›å»ºï¼ˆsource_textæœ‰å€¼ï¼‰ |
| è§„åˆ™é…ç½® | ç¡¬ç¼–ç åœ¨task_splitter.py | YAMLé…ç½®æ–‡ä»¶ |
| å¤„ç†å™¨é€‰æ‹© | è‡ªåŠ¨è¯†åˆ« | æ˜¾å¼æŒ‡å®š |
| é˜¶æ®µé“¾æ¥ | éšå¼ï¼ˆåŒä¸€Sessionï¼‰ | æ˜¾å¼ï¼ˆparent_session_idï¼‰ |
| ç‹¬ç«‹æµ‹è¯• | å›°éš¾ | ç®€å• |

### è¿ç§»æ£€æŸ¥æ¸…å•

- [ ] åˆ é™¤task_splitter.pyä¸­çš„CAPSç¡¬ç¼–ç é€»è¾‘ï¼ˆ273-294è¡Œï¼‰
- [ ] åˆå¹¶Analyze APIåˆ°Split API
- [ ] ä¿®æ”¹Split APIæ”¯æŒfileæˆ–parent_session_id
- [ ] ä¿®æ”¹Execute APIæ”¯æŒprocessorå‚æ•°
- [ ] åˆ›å»ºRuleFactoryå’ŒProcessorFactory
- [ ] æ·»åŠ config/rules.yamlå’Œconfig/processors.yaml
- [ ] å®ç°UppercaseProcessor
- [ ] æ›´æ–°å‰ç«¯æµ‹è¯•é¡µé¢æ”¯æŒä¸¤é˜¶æ®µæµç¨‹
- [ ] ç¼–å†™Sessioné“¾æ¥çš„å•å…ƒæµ‹è¯•
- [ ] æ›´æ–°APIæ–‡æ¡£

è¯¦ç»†å®æ–½è®¡åˆ’è¯·æŸ¥çœ‹ï¼š`.claude/PIPELINE_REFACTOR_PLAN.md`

## Known Limitations

### å½“å‰æ¶æ„é™åˆ¶

1. **Memory-Only Architecture**: No data persistence, sessions lost on restart
2. **No Horizontal Scaling**: Cannot distribute across multiple servers
3. **8-Hour Session Timeout**: Fixed timeout, not configurable per session
4. **CAPSä»»åŠ¡æ•°æ®å®Œæ•´æ€§é—®é¢˜**: CAPSä»»åŠ¡åœ¨ç¿»è¯‘å‰åˆ›å»ºï¼Œsource_textä¸ºç©ºï¼ˆæ–°æ¶æ„å·²è§£å†³ï¼‰

### æ–°æ¶æ„æ”¹è¿›

âœ… **è§£å†³çš„é—®é¢˜:**
- SessionèŒè´£å•ä¸€ï¼Œæ˜“äºæµ‹è¯•å’Œç»´æŠ¤
- CAPSä»»åŠ¡åœ¨ç¿»è¯‘ååˆ›å»ºï¼Œæ•°æ®å®Œæ•´æ€§ä¿è¯
- é…ç½®é©±åŠ¨ï¼Œæ‰©å±•æ€§å¼º
- æ˜¾å¼ä¾èµ–ç®¡ç†ï¼Œæ˜“äºç†è§£
- **å¤šç”¨æˆ·å¹¶å‘æ”¯æŒ** â­ NEW:
  - æ¯ä¸ªsessionæ‹¥æœ‰ç‹¬ç«‹çš„WorkerPoolå®ä¾‹
  - å¤šä¸ªç”¨æˆ·å¯ä»¥åŒæ—¶æ‰§è¡Œä¸åŒsessionçš„ä»»åŠ¡
  - WorkerPoolManagerç»Ÿä¸€ç®¡ç†æ‰€æœ‰sessionçš„æ‰§è¡ŒçŠ¶æ€
  - æ”¯æŒsessionçº§åˆ«çš„ç‹¬ç«‹æ§åˆ¶ï¼ˆstart/stop/pause/resumeï¼‰

âš ï¸ **ä»ç„¶å­˜åœ¨çš„é™åˆ¶:**
- Memory-Onlyï¼ˆçŸ­æœŸå†…ä¸å˜ï¼‰
- 8-Hour Timeoutï¼ˆçŸ­æœŸå†…ä¸å˜ï¼‰
- No Horizontal Scalingï¼ˆçŸ­æœŸå†…ä¸å˜ï¼‰

## Troubleshooting

### Backend Won't Start
- Check port 8013 is available
- Verify Python 3.8+ installed
- Ensure all requirements installed: `pip install -r requirements.txt`

### Translation Fails
- Check LLM API keys in environment variables or config
- Verify network connectivity to LLM endpoints
- Review logs for rate limiting errors
- Check `max_chars_per_batch` isn't too high for model limits

### Frontend Can't Connect
- Verify backend is running on expected port
- Check CORS settings in backend config
- Ensure WebSocket connections aren't blocked
- Review browser console for errors

### Session Lost
- Sessions expire after 8 hours
- Server restart clears all sessions
- No recovery mechanism - must re-upload file
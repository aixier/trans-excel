# Unified Configuration for Translation System Backend V2

# System configuration
system:
  max_memory_usage: 4096
  log_level: INFO
  session_timeout: 3600  # seconds

# API configuration
api:
  host: "0.0.0.0"
  port: 8013
  cors_origins: ["*"]

# Task execution control - 任务拆解和批次控制
task_execution:
  # Task splitting control - 任务拆解控制
  batch_control:
    max_chars_per_batch: 1000      # 每批次最大字符数（用于任务拆解）
    max_concurrent_workers: 10     # 最大并发worker数

  # Split operation parameters - 拆解操作参数 (reserved for future use)
  # split_control:
  #   max_task_chars: 500           # 单个任务最大字符数 (未使用)
  #   context_overlap: 50           # 上下文重叠字符数 (未使用)
  #   min_batch_size: 1             # 最小批次大小 (未使用)

# LLM configuration - LLM API配置
llm:
  # Default LLM provider
  default_provider: qwen-plus

  # LLM Providers configuration
  providers:
    openai:
      enabled: true
      api_key: ${OPENAI_API_KEY}  # Set via environment variable
      base_url: "https://api.openai.com/v1"
      model: "gpt-4-turbo-preview"
      temperature: 0.3
      max_tokens: 8000              # LLM API最大输出token数
      timeout: 90
      max_retries: 3
      retry_delay: 3.0

    gpt-5-nano:
      enabled: true
      api_key: ${OPENAI_GPT5_API_KEY}  # Set via environment variable
      base_url: "https://api.openai.com/v1"
      model: "gpt-5-nano"
      temperature: 0.3
      max_tokens: 8000              # LLM API最大输出token数
      timeout: 90
      max_retries: 3
      retry_delay: 3.0
      description: "OpenAI GPT-5 Nano - Experimental model"

    qwen:
      enabled: true
      api_key: "sk-4c89a24b73d24731b86bf26337398cef"
      base_url: "https://dashscope.aliyuncs.com/api/v1"
      model: "qwen-max"
      temperature: 0.3
      max_tokens: 8000              # LLM API最大输出token数
      timeout: 90
      max_retries: 3
      retry_delay: 3.0

    qwen-plus:
      enabled: true
      api_key: "sk-4c89a24b73d24731b86bf26337398cef"
      base_url: "https://dashscope.aliyuncs.com/api/v1"
      model: "qwen-plus"
      temperature: 0.3
      max_tokens: 8000              # LLM API最大输出token数
      timeout: 90
      max_retries: 3
      retry_delay: 3.0
      description: "阿里云通义千问Plus - 平衡性能和成本"

    # Additional providers can be added here
    # gemini:
    #   enabled: false
    #   api_key: ${GEMINI_API_KEY}
    #   base_url: "https://generativelanguage.googleapis.com/v1"
    #   model: "gemini-pro"
    #   temperature: 0.3
    #   max_tokens: 4000

  # Retry configuration
  retry:
    max_attempts: 3
    delay_seconds: 5.0
    exponential_backoff: true
    max_delay_seconds: 60.0

  # Cost tracking (per 1000 tokens)
  cost_estimation:
    gpt-4: 0.03
    gpt-4-turbo: 0.01
    gpt-4-turbo-preview: 0.01
    gpt-3.5-turbo: 0.002
    qwen-max: 0.008
    qwen-plus: 0.004
    qwen-turbo: 0.002

# Logging configuration
logging:
  level: INFO
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/translation_system.log"
  max_size: 10485760  # 10MB
  backup_count: 5

# Session configuration
session:
  timeout_hours: 1
  cleanup_interval_minutes: 30
  max_sessions: 100
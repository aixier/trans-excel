# LLM API配置模板 - 支持多种模型
# ================================================

# API基础配置
DASHSCOPE_API_KEY=your-api-key-here
LLM_BASE_URL=https://api.openai.com/v1
LLM_MODEL=gpt-3.5-turbo

# 模型限制配置（留空表示无限制）
# ================================================

# 速率限制
LLM_MAX_RPM=          # 每分钟最大请求数（如：3500 for GPT-3.5, 5000 for GPT-4, 15000 for qwen-plus）
LLM_MAX_TPM=          # 每分钟最大token数（如：90000 for GPT-3.5, 150000 for GPT-4, 1200000 for qwen-plus）

# 单次请求限制
LLM_MAX_INPUT_TOKENS=   # 单次最大输入token（如：16385 for GPT-3.5, 128000 for GPT-4, 98304 for qwen-plus）
LLM_MAX_OUTPUT_TOKENS=  # 单次最大输出token（如：4096 for GPT-3.5, 4096 for GPT-4, 16384 for qwen-plus）

# 批处理API配置（仅阿里云）
LLM_BATCH_ENABLED=false        # 是否支持批处理API
LLM_BATCH_MAX_INPUT_TOKENS=    # 批处理最大输入token
LLM_BATCH_MAX_OUTPUT_TOKENS=   # 批处理最大输出token

# ================================================
# 预设配置示例
# ================================================

# OpenAI GPT-3.5-turbo
# --------------------
# LLM_BASE_URL=https://api.openai.com/v1
# LLM_MODEL=gpt-3.5-turbo
# LLM_MAX_RPM=3500
# LLM_MAX_TPM=90000
# LLM_MAX_INPUT_TOKENS=16385
# LLM_MAX_OUTPUT_TOKENS=4096

# OpenAI GPT-4
# ------------
# LLM_BASE_URL=https://api.openai.com/v1
# LLM_MODEL=gpt-4
# LLM_MAX_RPM=500
# LLM_MAX_TPM=150000
# LLM_MAX_INPUT_TOKENS=128000
# LLM_MAX_OUTPUT_TOKENS=4096

# OpenAI GPT-4o-mini
# ------------------
# LLM_BASE_URL=https://api.openai.com/v1
# LLM_MODEL=gpt-4o-mini
# LLM_MAX_RPM=5000
# LLM_MAX_TPM=200000
# LLM_MAX_INPUT_TOKENS=128000
# LLM_MAX_OUTPUT_TOKENS=16384

# 阿里云 Qwen-Plus
# ----------------
# LLM_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
# LLM_MODEL=qwen-plus
# LLM_MAX_RPM=15000
# LLM_MAX_TPM=1200000
# LLM_MAX_INPUT_TOKENS=98304
# LLM_MAX_OUTPUT_TOKENS=16384
# LLM_BATCH_ENABLED=true
# LLM_BATCH_MAX_INPUT_TOKENS=6000000
# LLM_BATCH_MAX_OUTPUT_TOKENS=6000000

# 阿里云 Qwen-Max
# ---------------
# LLM_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
# LLM_MODEL=qwen-max
# LLM_MAX_RPM=2000
# LLM_MAX_TPM=2000000
# LLM_MAX_INPUT_TOKENS=30000
# LLM_MAX_OUTPUT_TOKENS=8000
# LLM_BATCH_ENABLED=true
# LLM_BATCH_MAX_INPUT_TOKENS=6000000
# LLM_BATCH_MAX_OUTPUT_TOKENS=6000000

# 阿里云 Qwen-Turbo
# -----------------
# LLM_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
# LLM_MODEL=qwen-turbo
# LLM_MAX_RPM=100000
# LLM_MAX_TPM=1000000
# LLM_MAX_INPUT_TOKENS=30000
# LLM_MAX_OUTPUT_TOKENS=8000
# LLM_BATCH_ENABLED=true
# === 翻译服务增强配置 ===
# 是否使用增强版翻译服务（带三层防护机制）
USE_ENHANCED_TRANSLATION=false

# 第一层：批次重试
ENABLE_TRANSLATION_RETRY=true
MAX_RETRY_ATTEMPTS=3

# 第二层：失败行小批次补充
ENABLE_COMPLETION_CHECK=true

# 第三层：单行翻译保障
ENABLE_SINGLE_ROW_FALLBACK=true

# RPM限制（请求每分钟）
TRANSLATION_RPM_LIMIT=300

# 批次配置
TRANSLATION_BATCH_SIZE=20
TRANSLATION_MAX_CONCURRENT=50
TRANSLATION_TIMEOUT=60

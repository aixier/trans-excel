# 任务拆分核心参数说明

## 一、两个核心参数的作用

### 1.1 max_chars_per_batch（单次LLM最大字符数）

**作用**：控制每个批次的大小，直接影响任务如何分组

```yaml
配置值: 50000  # 可根据模型能力调整

影响:
  - 决定一个批次能包含多少个任务
  - 控制单次LLM请求的数据量
  - 影响Token使用和成本
```

**任务拆分逻辑**：
```
输入: 1000个任务，每个1-1000字符不等
处理流程:
  1. 累积任务字符数
  2. 当累积接近50000时，创建新批次
  3. 保证单元格完整（不会在49999处截断）

结果示例:
  批次1: 80个小任务（共48000字符）
  批次2: 1个大任务（45000字符）
  批次3: 150个极小任务（共49500字符）
```

### 1.2 max_concurrent_workers（LLM最大并发数）

**作用**：控制同时执行的批次数量，影响整体处理速度

```yaml
配置值: 10  # 可根据API限制调整

影响:
  - 决定同时处理多少个批次
  - 控制API并发请求数
  - 影响总体完成时间
```

**并发执行示例**：
```
总批次数: 50个
并发数: 10

执行过程:
  时刻1: Worker1-10 各处理1个批次（共10个）
  时刻2: 完成的Worker获取新批次
  ...
  总耗时: 50批次 ÷ 10并发 = 约5轮完成
```

## 任务类型定义

### 三种任务类型

1. **普通翻译任务（Normal）**
   - 定义：需要将源语言翻译到目标语言的标准任务
   - 计算方式：有源文本的行数 × 目标语言列数
   - 示例：100行EN文本 × 3个目标语言(TR/TH/PT) = 300个任务

2. **黄色重新翻译任务（Yellow）**
   - 定义：标记为黄色的单元格，需要重新翻译到其后的所有列
   - 计算方式：黄色单元格数 × 该单元格后的所有列数（无论是否有内容）
   - 特点：即使目标列已有内容也要重新翻译覆盖
   - 示例：74个黄色EN单元格 × 1个TR列 = 74个任务

3. **蓝色缩短翻译任务（Blue）**
   - 定义：标记为蓝色的单元格，需要缩短翻译到自身格子
   - 计算方式：蓝色格子数（一对一）
   - 特点：翻译结果写回到原单元格（缩短版本）
   - 示例：3个蓝色单元格 = 3个任务

### 注释处理
- 所有三种任务类型都需要读取单元格注释
- 注释作为翻译上下文的一部分
- 注释可包含翻译指导、术语说明等信息

## 二、参数配置对任务拆分的影响

### 2.1 不同配置场景

| 场景 | max_chars_per_batch | max_concurrent_workers | 效果 |
|------|-------------------|----------------------|------|
| **高吞吐** | 80000 | 20 | 大批次+高并发，快速处理 |
| **稳定优先** | 30000 | 5 | 小批次+低并发，稳定可靠 |
| **成本优化** | 50000 | 10 | 平衡批次大小，减少Token浪费 |
| **质量优先** | 20000 | 3 | 小批次便于检查，低并发减少错误 |

### 2.2 动态调整策略

```yaml
自动调整规则:
  # 根据任务特征调整
  - 如果平均字符数 < 100:
      增加 max_chars_per_batch 到 80000  # 小任务可以多打包

  - 如果平均字符数 > 500:
      减少 max_chars_per_batch 到 30000  # 大任务需要少打包

  # 根据API响应调整
  - 如果频繁超时:
      减少 max_chars_per_batch         # 减小批次
      减少 max_concurrent_workers      # 降低并发

  - 如果响应很快:
      增加 max_concurrent_workers      # 提高并发利用率
```

## 三、任务拆分算法使用这些参数

### 3.1 拆分流程

```
步骤1: 读取配置
  max_chars = config['max_chars_per_batch']  # 50000
  max_workers = config['max_concurrent_workers']  # 10

步骤2: 创建批次
  对每个目标语言（PT/TH/VN）:
    当前批次 = []
    当前字符数 = 0

    对每个任务:
      任务字符数 = len(源文本) + len(上下文)

      如果 当前字符数 + 任务字符数 > max_chars:
        保存当前批次
        开始新批次
      否则:
        添加到当前批次

步骤3: 分配Worker
  批次队列 = [所有批次]
  活跃Workers = min(len(批次队列), max_workers)

  并发执行批次...
```

### 3.2 实际案例

**案例1：UI文本翻译**
```yaml
任务特征:
  - 总任务数: 500个
  - 平均字符: 20个/任务
  - 总字符数: 10000

使用参数:
  max_chars_per_batch: 50000
  max_concurrent_workers: 10

拆分结果:
  - 批次数: 1个（所有任务一批）
  - 执行时间: 1批 × 2秒 = 2秒
```

**案例2：对话文本翻译**
```yaml
任务特征:
  - 总任务数: 200个
  - 平均字符: 500个/任务
  - 总字符数: 100000

使用参数:
  max_chars_per_batch: 50000
  max_concurrent_workers: 10

拆分结果:
  - 批次数: 3个（100个+80个+20个任务）
  - 执行时间: 3批 ÷ 10并发 = 1轮 × 2秒 = 2秒
```

**案例3：混合文本翻译**
```yaml
任务特征:
  - 总任务数: 1000个
  - 字符分布: 1-1000不等
  - 总字符数: 300000

使用参数:
  max_chars_per_batch: 50000
  max_concurrent_workers: 10

拆分结果:
  - 批次数: 约7-8个
  - 执行时间: 8批 ÷ 10并发 = 1轮 × 2秒 = 2秒
```

## 四、参数优化建议

### 4.1 如何确定最优值

| 考虑因素 | 检查项 | 调整方向 |
|---------|--------|---------|
| **模型能力** | Token限制 | max_chars不超过模型输入限制的50% |
| **API限制** | RPM/TPM | max_workers不超过RPM÷60 |
| **任务特征** | 平均字符数 | 字符多则减小批次，字符少则增大批次 |
| **性能要求** | 完成时间 | 时间要求紧则增加并发 |
| **稳定性** | 错误率 | 错误多则减小批次和并发 |

### 4.2 推荐初始值

```yaml
# 保守配置（稳定优先）
conservative:
  max_chars_per_batch: 30000
  max_concurrent_workers: 5

# 标准配置（平衡）
standard:
  max_chars_per_batch: 50000
  max_concurrent_workers: 10

# 激进配置（速度优先）
aggressive:
  max_chars_per_batch: 80000
  max_concurrent_workers: 20
```

## 五、监控和调优

### 5.1 关键指标监控

```yaml
监控指标:
  批次维度:
    - 平均批次大小（字符数）
    - 批次内任务数分布
    - 批次执行时间

  并发维度:
    - Worker利用率
    - 队列等待时间
    - 并发冲突率

  效果维度:
    - 总处理时间
    - 错误率
    - Token使用效率
```

### 5.2 调优决策树

```
如果 完成时间过长:
  → 检查 Worker利用率
    如果 < 80%: 增加 max_concurrent_workers
    如果 = 100%: 检查批次大小
      如果批次过大: 减少 max_chars_per_batch

如果 错误率过高:
  → 检查 批次大小
    如果 > 60000: 减少到 40000
  → 检查 并发数
    如果 > 15: 减少到 10

如果 成本过高:
  → 增加 max_chars_per_batch（更好的批处理）
  → 优化 source_context（减少冗余信息）
```

## 六、总结

**核心要点**：

1. **max_chars_per_batch** 决定批次大小，影响效率和成本
2. **max_concurrent_workers** 决定处理速度，影响完成时间
3. 两个参数需要根据实际情况动态调整
4. 最优配置取决于任务特征、API限制和业务需求

**最佳实践**：
- 从标准配置（50000/10）开始
- 根据实际运行情况逐步调优
- 建立监控机制，自动调整参数
- 为不同类型任务准备不同配置预设
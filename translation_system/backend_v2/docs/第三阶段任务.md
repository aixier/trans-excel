# 第三阶段任务列表 - 持久化与导出优化

## 阶段目标
实现数据持久化、结果导出、性能优化，以及批处理效率提升

## 任务列表

| 序号 | 状态 | 任务名称 | 目标 | 参考文件 | 依赖 |
|------|------|----------|------|----------|------|
| 3.1 | ✅ | 批量翻译优化 | 优化LLM调用，支持单次请求处理多个任务 | `services/llm/batch_translator.py` | 2.6 |
| 3.2 | ✅ | 结果回写服务 | 将翻译结果回写到Excel DataFrame | `services/persistence/excel_writer.py` | 3.1 |
| 3.3 | ✅ | MySQL持久化层 | 实现MySQL数据库表结构和连接池 | `database/mysql_connector.py` | - |
| 3.4 | ✅ | 任务状态持久化 | 定时保存任务状态到MySQL | `services/persistence/task_persister.py` | 3.3 |
| 3.5 | ✅ | 检查点服务 | 实现检查点保存和恢复机制 | `services/persistence/checkpoint_service.py` | 3.3, 3.4 |
| 3.6 | ✅ | Excel导出优化 | 生成包含翻译结果的最终Excel | `services/export/excel_exporter.py` | 3.2 |
| 3.7 | ✅ | 下载API | GET /api/download/{session_id} 下载最终Excel | `api/download_api.py` | 3.6 |
| 3.8 | ✅ | 进度实时更新 | 优化进度更新机制，实现实时反馈 | `services/executor/progress_tracker.py` | 2.7 |
| 3.9 | ✅ | 批次动态调整 | 根据响应时间动态调整批次大小 | `services/executor/batch_optimizer.py` | 3.1 |
| 3.10 | ✅ | 成本计算优化 | 准确计算各LLM provider的成本 | `services/llm/cost_calculator.py` | 2.14 |
| 3.11 | ✅ | 断点续传 | 支持执行中断后从断点继续 | `services/executor/resume_handler.py` | 3.5 |
| 3.12 | ✅ | 日志持久化 | 将执行日志保存到文件和数据库 | `services/logging/log_persister.py` | 3.3 |
| 3.13 | ✅ | 性能监控 | 实时监控系统性能指标 | `services/monitor/performance_monitor.py` | 2.10 |
| 3.14 | ✅ | 清理服务 | 定期清理过期session和临时文件 | `services/cleanup/session_cleaner.py` | 3.4 |
| 3.15 | ✅ | WebSocket推送 | 实现进度和状态的WebSocket实时推送 | `api/websocket_api.py` | 2.15 |

## 详细设计

### 3.1 批量翻译优化
```python
# services/llm/batch_translator.py
class BatchTranslator:
    def __init__(self, provider: BaseLLMProvider):
        self.provider = provider
        self.batch_size = 5  # 每次发送5个任务

    async def translate_batch_optimized(
        self,
        tasks: List[Dict]
    ) -> List[Dict]:
        """优化的批量翻译，将多个任务合并为一个请求"""
        # 1. 将多个任务合并成一个prompt
        # 2. 调用LLM一次
        # 3. 解析返回的多个翻译结果
        # 4. 分配回各个任务
```

### 3.2 结果回写服务
```python
# services/persistence/excel_writer.py
class ExcelWriter:
    async def write_back_results(
        self,
        session_id: str,
        task_df: pd.DataFrame
    ):
        """将翻译结果回写到原始Excel DataFrame"""
        # 1. 获取Excel DataFrame集合
        # 2. 根据task_df中的位置信息
        # 3. 将result写回对应单元格
        # 4. 更新单元格颜色（完成=灰色）
```

### 3.3 MySQL持久化层
```sql
-- database/schema.sql
CREATE TABLE translation_sessions (
    session_id VARCHAR(36) PRIMARY KEY,
    filename VARCHAR(255),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    status ENUM('created', 'analyzing', 'splitting', 'executing', 'completed', 'failed'),
    total_tasks INT,
    completed_tasks INT,
    failed_tasks INT,
    game_info JSON,
    metadata JSON
);

CREATE TABLE translation_tasks (
    task_id VARCHAR(20) PRIMARY KEY,
    session_id VARCHAR(36),
    batch_id VARCHAR(20),
    group_id VARCHAR(20),
    source_text TEXT,
    source_lang VARCHAR(10),
    target_lang VARCHAR(10),
    result TEXT,
    status ENUM('pending', 'processing', 'completed', 'failed'),
    confidence FLOAT,
    token_count INT,
    cost DECIMAL(10, 6),
    error_message TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    completed_at TIMESTAMP,
    FOREIGN KEY (session_id) REFERENCES translation_sessions(session_id),
    INDEX idx_session_batch (session_id, batch_id),
    INDEX idx_status (status)
);

CREATE TABLE execution_logs (
    log_id BIGINT AUTO_INCREMENT PRIMARY KEY,
    session_id VARCHAR(36),
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    level VARCHAR(10),
    message TEXT,
    details JSON,
    INDEX idx_session_time (session_id, timestamp)
);
```

### 3.4 任务状态持久化
```python
# services/persistence/task_persister.py
class TaskPersister:
    def __init__(self, db_pool):
        self.db_pool = db_pool
        self.persist_interval = 30  # 30秒

    async def start_auto_persist(self, session_id: str):
        """启动自动持久化任务"""
        while True:
            await self.persist_tasks(session_id)
            await asyncio.sleep(self.persist_interval)

    async def persist_tasks(self, session_id: str):
        """持久化任务到MySQL"""
        # 1. 获取任务DataFrame
        # 2. 筛选未持久化或已更新的任务
        # 3. 批量插入/更新MySQL
        # 4. 标记已持久化
```

### 3.5 检查点服务
```python
# services/persistence/checkpoint_service.py
class CheckpointService:
    def __init__(self):
        self.checkpoint_dir = Path("./checkpoints")

    async def save_checkpoint(self, session_id: str):
        """保存检查点"""
        # 1. 获取当前任务DataFrame
        # 2. 序列化为pickle或parquet
        # 3. 保存到文件系统
        # 4. 记录检查点元信息

    async def restore_checkpoint(self, session_id: str):
        """恢复检查点"""
        # 1. 查找最新检查点
        # 2. 加载DataFrame
        # 3. 恢复session状态
        # 4. 返回恢复点信息
```

### 3.6 Excel导出优化
```python
# services/export/excel_exporter.py
class ExcelExporter:
    async def export_final_excel(
        self,
        session_id: str
    ) -> str:
        """导出最终的Excel文件"""
        # 1. 获取原始Excel DataFrame集合
        # 2. 获取任务DataFrame的翻译结果
        # 3. 将结果填充到对应位置
        # 4. 更新颜色和格式
        # 5. 保存为新的Excel文件
        # 6. 返回文件路径
```

### 3.7 下载API
```python
# api/download_api.py
@router.get("/download/{session_id}")
async def download_translated_excel(session_id: str):
    """
    下载翻译完成的Excel文件

    Returns:
        FileResponse: 翻译后的Excel文件
    """
    # 1. 检查session状态
    # 2. 调用ExcelExporter生成文件
    # 3. 返回FileResponse
```

### 3.8 进度实时更新
```python
# services/executor/progress_tracker.py
class ProgressTracker:
    def __init__(self):
        self.progress_cache = {}

    async def update_task_progress(
        self,
        task_id: str,
        status: str
    ):
        """更新单个任务进度"""
        # 1. 立即更新DataFrame
        # 2. 更新进度缓存
        # 3. 触发WebSocket通知（如果启用）
```

### 3.9 批次动态调整
```python
# services/executor/batch_optimizer.py
class BatchOptimizer:
    def __init__(self):
        self.response_times = []
        self.current_batch_size = 5

    def optimize_batch_size(
        self,
        response_time: float
    ) -> int:
        """根据响应时间动态调整批次大小"""
        # 1. 记录响应时间
        # 2. 计算平均响应时间
        # 3. 如果响应快，增加批次大小
        # 4. 如果响应慢或超时，减少批次大小
        # 5. 返回优化后的批次大小
```

## 配置文件更新
```yaml
# config/database.yaml
mysql:
  host: localhost
  port: 3306
  database: translation_system
  username: ${MYSQL_USER}
  password: ${MYSQL_PASSWORD}
  pool_size: 10
  max_overflow: 20

persistence:
  checkpoint_interval: 60      # 检查点保存间隔（秒）
  auto_persist_interval: 30    # 自动持久化间隔（秒）
  cleanup_interval: 3600       # 清理间隔（秒）
  session_ttl: 86400          # Session过期时间（秒）

export:
  temp_dir: ./temp/exports
  output_dir: ./output
  keep_temp_files: false
```

## 测试计划

### 单元测试
1. **批量翻译测试**
   - 测试任务合并逻辑
   - 测试结果拆分逻辑
   - 测试错误处理

2. **持久化测试**
   - 测试MySQL连接池
   - 测试事务处理
   - 测试检查点保存/恢复

3. **导出测试**
   - 测试Excel生成
   - 测试格式保持
   - 测试大文件处理

### 集成测试
```python
# tests/test_full_flow.py
async def test_complete_flow_with_persistence():
    """测试包含持久化的完整流程"""
    # 1. 上传Excel
    # 2. 拆分任务
    # 3. 执行翻译（批量优化）
    # 4. 验证持久化
    # 5. 模拟中断和恢复
    # 6. 下载最终结果
    # 7. 验证结果正确性
```

## 性能优化目标

### 批量翻译优化
- 前：27个任务需要27次API调用（1任务/请求）
- 后：27个任务需要6次API调用（5任务/请求）
- 预期提升：执行时间从40秒降到10-15秒

### 进度更新优化
- 前：批次完成后一次性更新（0% -> 100%）
- 后：每个任务完成立即更新（渐进式）
- 用户体验：实时看到进度变化

### 持久化性能
- MySQL批量插入：1000条/秒
- 检查点保存：<1秒
- 不影响主流程执行

## 依赖安装
```bash
pip install aiomysql  # 异步MySQL客户端
pip install websockets  # WebSocket支持
pip install aiofiles  # 异步文件操作
```

## 验收标准
- [ ] 批量翻译将API调用次数减少80%
- [ ] 进度更新延迟<1秒
- [ ] 支持执行中断后恢复
- [ ] MySQL持久化不影响执行性能
- [ ] 导出的Excel保持原始格式
- [ ] 清理服务自动运行
- [ ] 成本计算准确度>95%

## 开发顺序建议
1. 先实现批量翻译优化(3.1)和进度实时更新(3.8) - 改善用户体验
2. 实现MySQL持久化(3.3-3.5) - 数据安全
3. 实现Excel导出和下载(3.2, 3.6, 3.7) - 核心功能
4. 添加性能优化(3.9, 3.13) - 提升效率
5. 最后添加辅助功能(3.10-3.12, 3.14-3.15) - 完善系统

## 注意事项
1. **批量翻译格式**：设计统一的批量请求和响应格式
2. **事务一致性**：MySQL操作使用事务确保数据一致性
3. **内存管理**：大文件处理时注意内存使用
4. **并发安全**：DataFrame更新需要加锁保护
5. **错误恢复**：每个服务都要有错误恢复机制
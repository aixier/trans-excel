# 渐进式开发计划 - 三阶段实施

## 总体架构

```
第一阶段：数据层 + 分析拆分服务
第二阶段：执行引擎 + 监控服务
第三阶段：持久化 + 导出服务
```

---

## 第一阶段：基础数据与任务拆分（3-4天）

### 1.1 数据存储层

#### Excel DataFrame集合
```yaml
功能: 存储原始Excel数据
结构:
  - Dict[sheet_name, pd.DataFrame]
  - color_map: 颜色映射
  - comment_map: 注释映射
```

#### 任务DataFrame
```yaml
功能: 存储所有任务信息
核心字段:
  - task_id: 任务ID
  - batch_id: 批次ID（基于max_chars_per_batch）
  - group_id: 分组ID
  - source_text: 源文本
  - target_lang: 目标语言
  - status: 任务状态
  - result: 翻译结果
```

### 1.2 Excel分析服务

#### API接口
```yaml
POST /api/analyze/upload
  请求:
    multipart/form-data:
      - file: Excel文件
      - game_info: JSON字符串
        {
          "game_type": "RPG/FPS/MOBA等",
          "world_view": "游戏世界观描述",
          "target_regions": ["BR", "TH", "VN"],
          "game_style": "写实/卡通/像素等",
          "additional_context": "其他补充信息"
        }
  响应:
    {
      "session_id": "uuid",
      "analysis": {
        "file_info": {
          "filename": "test.xlsx",
          "sheets": ["Sheet1"],
          "total_rows": 100,
          "total_cols": 5
        },
        "language_detection": {
          "source_langs": ["CH", "EN"],
          "target_langs": ["PT", "TH", "VN"]
        },
        "statistics": {
          "total_cells": 500,
          "non_empty_cells": 300,
          "estimated_tasks": 150
        }
      }
    }
```

### 1.3 任务拆分服务

#### 配置文件
```yaml
# config.yaml
llm:
  batch_control:
    max_chars_per_batch: 50000  # 核心参数1
    max_concurrent_workers: 10   # 核心参数2
```

#### API接口
```yaml
POST /api/tasks/split
  请求:
    {
      "session_id": "uuid",
      "source_lang": "CH",  # 指定源语言（可选，默认使用检测结果）
      "target_langs": ["PT", "TH", "VN"]  # 指定目标语言列表
    }
  响应:
    {
      "task_count": 150,
      "batch_count": 8,
      "preview": [...],  # 前10条任务
      "download_url": "/api/tasks/export/{session_id}"
    }

GET /api/tasks/export/{session_id}
  响应: Excel文件（任务DataFrame导出，用于过程观测）
```

#### 任务拆分逻辑
1. 遍历Excel单元格，识别需要翻译的任务
2. 提取source_context上下文
3. 分配group_id（按Sheet或内容类型）
4. **基于max_chars_per_batch动态分配batch_id**
5. 生成任务DataFrame存储在内存

### 1.4 第一阶段验证

- [ ] 能上传Excel并获得分析报告
- [ ] 能生成任务DataFrame
- [ ] batch_id按字符数正确分配
- [ ] 能导出任务Excel查看

---

## 第二阶段：执行引擎与监控（4-5天）

### 2.1 LLM执行引擎

#### API接口
```yaml
POST /api/execute/start
  请求:
    {
      "session_id": "uuid"
    }
  响应:
    {
      "status": "started",
      "total_batches": 8,
      "workers": 10
    }
```

#### 执行逻辑
1. 读取任务DataFrame
2. 获取pending状态的批次
3. **使用max_concurrent_workers创建Worker池**
4. 并发执行批次翻译
5. **直接更新任务DataFrame的result和status字段**

### 2.2 监控服务

#### API接口
```yaml
GET /api/monitor/status/{session_id}
  响应:
    {
      "progress": {
        "total": 150,
        "completed": 75,
        "processing": 10,
        "pending": 65,
        "failed": 0
      },
      "completion_rate": 50.0,
      "estimated_remaining": 120,  # 秒
      "current_batches": [...],
      "recent_completions": [...]
    }

GET /api/monitor/dataframe/{session_id}
  参数:
    - status: completed/pending/failed（可选）
    - limit: 100（可选）
  响应: 任务DataFrame的JSON格式（最新内容）
```

### 2.3 第二阶段验证

- [ ] 能启动执行
- [ ] Worker并发数符合配置
- [ ] 结果直接写入DataFrame
- [ ] 监控API返回实时进度
- [ ] 能查询最新DataFrame内容

---

## 第三阶段：持久化与导出（3-4天）

### 3.1 持久化服务

#### 自动持久化逻辑
```yaml
定时任务:
  1. 回写Excel DataFrame:
     - 每30秒检查已完成任务
     - 将result回写到Excel DataFrame对应单元格
     - 更新颜色状态（完成变灰色）

  2. MySQL存储:
     - 每60秒保存检查点
     - 存储任务状态到MySQL
     - 标记已持久化任务
```

#### MySQL表结构
```sql
-- 简化的表结构
CREATE TABLE translation_sessions (
    session_id VARCHAR(36) PRIMARY KEY,
    filename VARCHAR(255),
    created_at TIMESTAMP,
    status VARCHAR(20),
    total_tasks INT,
    completed_tasks INT
);

CREATE TABLE translation_tasks (
    task_id VARCHAR(20) PRIMARY KEY,
    session_id VARCHAR(36),
    source_text TEXT,
    target_lang VARCHAR(10),
    result TEXT,
    status VARCHAR(20),
    created_at TIMESTAMP,
    completed_at TIMESTAMP,
    INDEX idx_session (session_id)
);
```

### 3.2 Excel下载接口

#### API接口
```yaml
GET /api/download/{session_id}
  响应:
    - 翻译完成的Excel文件
    - 保持原始格式
    - 已翻译内容填充到对应单元格
    - 颜色标记更新（完成=灰色）
```

### 3.3 第三阶段验证

- [ ] DataFrame自动回写Excel
- [ ] MySQL定时存储工作
- [ ] 能下载最终Excel
- [ ] 翻译结果位置正确

---

## 技术栈

```yaml
后端框架: FastAPI
数据处理: pandas
Excel处理: openpyxl
数据库: MySQL
LLM接口: OpenAI/阿里云SDK
配置管理: pyyaml
```

## 部署结构

```yaml
docker-compose.yml:
  services:
    api:
      image: translation-api:v3
      ports: ["8000:8000"]
      volumes:
        - ./config:/app/config
        - ./data:/app/data

    mysql:
      image: mysql:8.0
      environment:
        MYSQL_ROOT_PASSWORD: password
        MYSQL_DATABASE: translation
```

## 开发优先级

### 必须实现
1. ✅ 两个DataFrame数据结构
2. ✅ Excel分析和任务拆分API
3. ✅ 基于字符数的batch_id分配
4. ✅ Worker并发执行
5. ✅ 监控查询接口
6. ✅ Excel下载接口

### 可选优化
1. ⚠️ 错误重试机制
2. ⚠️ 任务优先级调度
3. ⚠️ 实时日志查看
4. ⚠️ 批次大小动态调整

## 测试计划

### 测试数据
```
test_data/
  - small.xlsx    # 10行，快速验证
  - medium.xlsx   # 100行，测试批次
  - large.xlsx    # 1000行，测试性能
  - mixed.xlsx    # 不同字符长度
```

### 测试场景
1. **第一阶段**：上传→分析→拆分→导出任务
2. **第二阶段**：执行→监控→查询进度
3. **第三阶段**：持久化→下载结果

## 时间规划

| 阶段 | 时间 | 交付物 |
|------|------|--------|
| 第一阶段 | 3-4天 | 分析服务、拆分服务、任务Excel导出 |
| 第二阶段 | 4-5天 | 执行引擎、监控API、DataFrame查询 |
| 第三阶段 | 3-4天 | 自动持久化、Excel下载 |
| **总计** | **10-13天** | **完整系统** |
"""
ç¿»è¯‘å¼•æ“æ ¸å¿ƒç±»
åŸºäºtest_concurrent_batch.pyçš„å®Œæ•´æ¶æ„åŒ–å®ç°
"""
import asyncio
import json
import pandas as pd
import time
from datetime import datetime
from typing import List, Dict, Optional
from openai import AsyncOpenAI
from config.settings import settings
from database.connection import AsyncSession
from project_manager.manager import ProjectManager
from .placeholder_protector import PlaceholderProtector
from .localization_engine import LocalizationEngine
from .terminology_manager import TerminologyManager
from excel_analysis.header_analyzer import HeaderAnalyzer
from excel_analysis.translation_detector import TranslationDetector
import logging

logger = logging.getLogger(__name__)


class TranslationEngine:
    """ç¿»è¯‘å¼•æ“ - åŸºäºDemoçš„æ¶æ„åŒ–å®ç°"""

    def __init__(self):
        self.client = AsyncOpenAI(
            api_key=settings.llm_api_key,
            base_url=settings.llm_base_url
        )
        self.project_manager = ProjectManager(None)  # OSS storage will be injected
        self.placeholder_protector = PlaceholderProtector()
        self.localization_engine = LocalizationEngine()
        self.terminology_manager = TerminologyManager()
        self.header_analyzer = HeaderAnalyzer()
        self.translation_detector = TranslationDetector()

        # ç»Ÿè®¡ä¿¡æ¯ (åŸºäºDemo)
        self.completed_batches = 0
        self.total_batches = 0
        self.failed_batches = []

    async def process_translation_task(
        self,
        db: AsyncSession,
        task_id: str,
        file_path: str,
        target_languages: List[str],
        batch_size: int = 3,
        max_concurrent: int = 10,
        max_iterations: int = 5,
        region_code: str = 'na',
        game_background: str = None,
        sheet_names: List[str] = None,  # None = å¤„ç†æ‰€æœ‰sheets
        auto_detect: bool = True  # è‡ªåŠ¨æ£€æµ‹éœ€è¦ç¿»è¯‘çš„sheets
    ):
        """å¤„ç†ç¿»è¯‘ä»»åŠ¡ - æ”¯æŒå¤šSheetå¤„ç†"""
        try:
            logger.info(f"å¼€å§‹å¤„ç†ç¿»è¯‘ä»»åŠ¡: {task_id}")

            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            await self.project_manager.update_task_progress(
                db, task_id, status='analyzing'
            )

            # 1. åˆ†æExcelæ–‡ä»¶ç»“æ„
            xl_file = pd.ExcelFile(file_path)
            all_sheet_names = xl_file.sheet_names
            logger.info(f"Excelæ–‡ä»¶åŒ…å« {len(all_sheet_names)} ä¸ªSheet: {all_sheet_names}")

            # 2. ç¡®å®šè¦å¤„ç†çš„sheets
            if sheet_names:
                sheets_to_process = [s for s in sheet_names if s in all_sheet_names]
            else:
                sheets_to_process = all_sheet_names

            # 3. è‡ªåŠ¨æ£€æµ‹éœ€è¦ç¿»è¯‘çš„sheets
            if auto_detect:
                sheets_to_process = await self._detect_translatable_sheets(
                    file_path, sheets_to_process, target_languages
                )

            logger.info(f"å°†å¤„ç† {len(sheets_to_process)}/{len(all_sheet_names)} ä¸ªSheets: {sheets_to_process}")

            if not sheets_to_process:
                logger.info("æ²¡æœ‰éœ€è¦ç¿»è¯‘çš„Sheet")
                await self.project_manager.update_task_progress(
                    db, task_id, status='completed'
                )
                return

            # 4. å­˜å‚¨æ‰€æœ‰Sheetçš„ç»“æœ
            all_results = {}
            total_translated = 0

            # 5. é€ä¸ªå¤„ç†æ¯ä¸ªSheet
            for sheet_idx, sheet_name in enumerate(sheets_to_process, 1):
                logger.info(f"\n{'='*50}")
                logger.info(f"å¤„ç†Sheet {sheet_idx}/{len(sheets_to_process)}: {sheet_name}")
                logger.info(f"{'='*50}")

                # åŠ è½½å½“å‰Sheet
                df = pd.read_excel(file_path, sheet_name=sheet_name)
                logger.info(f"Sheet '{sheet_name}' åŠ è½½æˆåŠŸï¼Œæ€»è¡Œæ•°: {len(df)}")

                # æ¸…ç†åˆ—åï¼ˆå»é™¤ç‰¹æ®Šå­—ç¬¦å¦‚å†’å·ï¼‰
                df.columns = [col.strip(':').strip() for col in df.columns]

                # åŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°ï¼ˆå¤§æ–‡ä»¶ä¼˜åŒ–ï¼‰
                if len(df) > 5000:
                    current_batch_size = min(30, batch_size * 3)  # æœ€å¤§30è¡Œ
                    logger.info(f"å¤§æ–‡ä»¶ä¼˜åŒ–ï¼šæ‰¹æ¬¡å¤§å°è°ƒæ•´ä¸º {current_batch_size}")
                elif len(df) > 1000:
                    current_batch_size = min(20, batch_size * 2)  # ä¸­ç­‰æ–‡ä»¶20è¡Œ
                    logger.info(f"ä¸­ç­‰æ–‡ä»¶ä¼˜åŒ–ï¼šæ‰¹æ¬¡å¤§å°è°ƒæ•´ä¸º {current_batch_size}")
                else:
                    current_batch_size = min(10, batch_size)  # å°æ–‡ä»¶10è¡Œ

                # 2. æ™ºèƒ½åˆ†æè¡¨å¤´ç»“æ„
                sheet_info = self.header_analyzer.analyze_sheet(df, sheet_name)
                logger.info(f"è¡¨å¤´åˆ†æå®Œæˆï¼Œå¯ç¿»è¯‘è¡Œæ•°: {sheet_info.translatable_rows}")

                # 3. æ£€æµ‹ç¿»è¯‘ä»»åŠ¡
                translation_tasks = self.translation_detector.detect_translation_tasks(df, sheet_info)
                logger.info(f"æ£€æµ‹åˆ°ç¿»è¯‘ä»»åŠ¡: {len(translation_tasks)}ä¸ª")

                if not translation_tasks:
                    logger.info(f"Sheet '{sheet_name}' æ²¡æœ‰éœ€è¦ç¿»è¯‘çš„å†…å®¹")
                    all_results[sheet_name] = df
                    continue

                # 4. åˆ›å»ºæ‰¹æ¬¡ (åŸºäºDemoçš„æ‰¹å¤„ç†é€»è¾‘)
                batches = self.translation_detector.group_tasks_by_batch(translation_tasks, current_batch_size)
                self.total_batches = len(batches)

                await self.project_manager.update_task_progress(
                    db, task_id,
                    status='translating',
                    current_sheet=sheet_name
                )

                # 5. è¿­ä»£ç¿»è¯‘ (åŸºäºDemoçš„è¿­ä»£é€»è¾‘)
                current_df = df.copy()
                iteration = 0

                while iteration < max_iterations:
                    iteration += 1
                    logger.info(f"Sheet '{sheet_name}' - å¼€å§‹ç¬¬{iteration}è½®è¿­ä»£ç¿»è¯‘")

                    # æ›´æ–°è¿­ä»£çŠ¶æ€
                    status = 'iterating' if iteration > 1 else 'translating'
                    await self.project_manager.update_task_progress(
                        db, task_id,
                        current_iteration=iteration,
                        status=status
                    )

                    # å¹¶å‘å¤„ç†æ‰¹æ¬¡ (åŸºäºDemoçš„å¹¶å‘é€»è¾‘)
                    semaphore = asyncio.Semaphore(max_concurrent)
                    translation_results = await self._process_batches_concurrent(
                        db, task_id, batches, target_languages, semaphore,
                        region_code, game_background, iteration
                    )

                    # åº”ç”¨ç¿»è¯‘ç»“æœåˆ°DataFrame
                    translated_count = self._apply_translation_results(current_df, translation_results)
                    total_translated += translated_count

                    # æ›´æ–°è¿›åº¦
                    await self.project_manager.update_task_progress(
                        db, task_id,
                        translated_rows=total_translated
                    )

                    # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                    remaining_tasks = self._count_remaining_tasks(current_df, sheet_info)
                    if remaining_tasks == 0:
                        logger.info(f"Sheet '{sheet_name}' - ç¬¬{iteration}è½®è¿­ä»£å®Œæˆæ‰€æœ‰ç¿»è¯‘")
                        break

                    logger.info(f"Sheet '{sheet_name}' - ç¬¬{iteration}è½®è¿­ä»£å®Œæˆï¼Œå‰©ä½™ä»»åŠ¡: {remaining_tasks}")

                # ä¿å­˜å½“å‰Sheetç»“æœ
                all_results[sheet_name] = current_df

            # 6. ä¿å­˜æ‰€æœ‰Sheetç»“æœå¹¶å®Œæˆä»»åŠ¡
            await self._save_multi_sheet_results(db, task_id, all_results, file_path)

        except Exception as e:
            logger.error(f"ç¿»è¯‘ä»»åŠ¡å¤„ç†å¤±è´¥: {task_id}, é”™è¯¯: {e}")
            await self.project_manager.update_task_progress(
                db, task_id,
                status='failed',
                error_message=str(e)
            )
            raise

    async def _process_batches_concurrent(
        self,
        db: AsyncSession,
        task_id: str,
        batches: List[List],
        target_languages: List[str],
        semaphore: asyncio.Semaphore,
        region_code: str,
        game_background: str,
        iteration: int
    ) -> Dict:
        """å¹¶å‘å¤„ç†æ‰¹æ¬¡ - åŸºäºDemoçš„å¹¶å‘é€»è¾‘"""
        tasks = []

        for batch_id, batch in enumerate(batches, 1):
            task = self._translate_batch_with_retry(
                db, task_id, batch, batch_id, target_languages,
                semaphore, region_code, game_background, iteration
            )
            tasks.append(task)

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰æ‰¹æ¬¡ (ä¸Demoé€»è¾‘ä¸€è‡´)
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # åˆå¹¶ç»“æœ
        translation_results = {}
        for result in results:
            if isinstance(result, dict):
                translation_results.update(result)
            else:
                logger.error(f"æ‰¹æ¬¡å¤„ç†å¤±è´¥: {result}")

        return translation_results

    async def _translate_batch_with_retry(
        self,
        db: AsyncSession,
        task_id: str,
        batch: List,
        batch_id: int,
        target_languages: List[str],
        semaphore: asyncio.Semaphore,
        region_code: str,
        game_background: str,
        iteration: int,
        max_retry_attempts: int = 2,
        retry_base_delay: float = 3.0
    ) -> Dict:
        """æ‰¹æ¬¡ç¿»è¯‘å¸¦é‡è¯•æœºåˆ¶ - åŸºäºDemoçš„é‡è¯•é€»è¾‘"""
        async with semaphore:
            start_time = time.time()
            logger.info(f"ğŸ“¦ æ‰¹æ¬¡{batch_id}: å¼€å§‹å¤„ç† {len(batch)}ä¸ªä»»åŠ¡")

            # å‡†å¤‡è¾“å…¥æ•°æ® (ä¸Demoæ ¼å¼ä¸€è‡´)
            input_texts = []
            for i, task in enumerate(batch):
                input_texts.append({
                    "id": f"batch_{batch_id}_text_{i}",
                    "text": task.source_text
                })

            # é‡è¯•æœºåˆ¶ (ä¸Demoé€»è¾‘ä¸€è‡´)
            for attempt in range(max_retry_attempts + 1):
                try:
                    if attempt > 0:
                        retry_delay = retry_base_delay * (2 ** (attempt - 1))
                        logger.info(f"ğŸ”„ æ‰¹æ¬¡{batch_id}: ç¬¬{attempt + 1}æ¬¡å°è¯•ï¼Œå»¶è¿Ÿ{retry_delay:.1f}s")
                        await asyncio.sleep(retry_delay)

                    # åˆ›å»ºåŒºåŸŸåŒ–æç¤ºè¯ (å‡çº§Demoçš„é€šç”¨æç¤ºè¯)
                    system_prompt = self.localization_engine.create_batch_prompt(
                        [task.source_text for task in batch],
                        target_languages,
                        region_code,
                        game_background,
                        batch[0].task_type if batch else 'new'
                    )

                    # æ„å»ºè¯·æ±‚æ¶ˆæ¯ (ä¸Demoæ ¼å¼ä¸€è‡´)
                    messages = [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": f"è¯·ç¿»è¯‘ä»¥ä¸‹ä¸­æ–‡æ–‡æœ¬ï¼š\n{json.dumps(input_texts, ensure_ascii=False, indent=2)}"}
                    ]

                    # è°ƒç”¨LLM API (ä¸Demoä¸€è‡´)
                    response = await self.client.chat.completions.create(
                        model=settings.llm_model,
                        messages=messages,
                        temperature=0.3,
                        max_tokens=4000,
                        response_format={"type": "json_object"},
                        timeout=90
                    )

                    # å¤„ç†å“åº” (ä¸Demoæ ¼å¼ä¸€è‡´)
                    result = json.loads(response.choices[0].message.content)
                    translations = result.get("translations", [])

                    # è®°å½•APIç»Ÿè®¡
                    api_calls = 1
                    tokens_used = response.usage.total_tokens if response.usage else 0

                    # å‡å°‘æ•°æ®åº“æ›´æ–°é¢‘ç‡ï¼Œåªåœ¨ç‰¹å®šæ‰¹æ¬¡æ›´æ–°
                    if batch_id % 5 == 0 or batch_id == self.total_batches:
                        try:
                            await self.project_manager.update_task_progress(
                                db, task_id,
                                api_calls=api_calls,
                                tokens_used=tokens_used
                            )
                        except Exception as update_error:
                            logger.warning(f"æ›´æ–°è¿›åº¦å¤±è´¥: {update_error}")

                    # æ„å»ºè¿”å›ç»“æœ
                    batch_results = {}
                    for i, translation in enumerate(translations):
                        if i < len(batch):
                            task = batch[i]
                            # åŠ¨æ€æ„å»ºç»“æœï¼Œæ ¹æ®å®é™…çš„ç›®æ ‡è¯­è¨€
                            lang_result = {}
                            for lang in target_languages:
                                lang_result[lang] = translation.get(lang, '')
                            batch_results[task.row_index] = lang_result

                    elapsed = time.time() - start_time
                    self.completed_batches += 1

                    retry_info = f" (ç¬¬{attempt + 1}æ¬¡å°è¯•)" if attempt > 0 else ""
                    logger.info(f"âœ… æ‰¹æ¬¡{batch_id}: å®Œæˆç¿»è¯‘{retry_info} {len(translations)}æ¡ | "
                              f"è€—æ—¶{elapsed:.1f}s | tokens: {tokens_used} | "
                              f"è¿›åº¦: {self.completed_batches}/{self.total_batches}")

                    return batch_results

                except Exception as e:
                    elapsed = time.time() - start_time

                    if attempt < max_retry_attempts:
                        logger.warning(f"âš ï¸ æ‰¹æ¬¡{batch_id}: ç¬¬{attempt + 1}æ¬¡å°è¯•å¤±è´¥ | é”™è¯¯: {e}")
                    else:
                        logger.error(f"âŒ æ‰¹æ¬¡{batch_id}: é‡è¯•{max_retry_attempts}æ¬¡åæœ€ç»ˆå¤±è´¥ | æ€»è€—æ—¶{elapsed:.1f}s | é”™è¯¯: {e}")
                        self.failed_batches.append(batch_id)

            return {}  # å¤±è´¥æ—¶è¿”å›ç©ºç»“æœ

    def _apply_translation_results(self, df: pd.DataFrame, results: Dict) -> int:
        """åº”ç”¨ç¿»è¯‘ç»“æœåˆ°DataFrame"""
        translated_count = 0

        for row_index, translations in results.items():
            for lang, translation in translations.items():
                if translation and translation.strip():
                    # æ‰¾åˆ°å¯¹åº”çš„è¯­è¨€åˆ— - æ›´ç²¾ç¡®çš„åŒ¹é…
                    lang_upper = lang.upper()
                    matched_col = None

                    # é¦–å…ˆå°è¯•ç²¾ç¡®åŒ¹é…
                    if lang_upper in df.columns:
                        matched_col = lang_upper
                    # å…¶æ¬¡å°è¯•å°å†™åŒ¹é…
                    elif lang.lower() in [col.lower() for col in df.columns]:
                        for col in df.columns:
                            if col.lower() == lang.lower():
                                matched_col = col
                                break

                    if matched_col:
                        df.at[row_index, matched_col] = translation
                        translated_count += 1
                        logger.debug(f"åº”ç”¨ç¿»è¯‘: è¡Œ{row_index}, åˆ—{matched_col} = {translation[:30]}...")
                    else:
                        logger.warning(f"æ‰¾ä¸åˆ°è¯­è¨€åˆ—: {lang} (å¯ç”¨åˆ—: {list(df.columns)})")

        return translated_count

    def _count_remaining_tasks(self, df: pd.DataFrame, sheet_info) -> int:
        """ç»Ÿè®¡å‰©ä½™ç¿»è¯‘ä»»åŠ¡æ•°é‡"""
        tasks = self.translation_detector.detect_translation_tasks(df, sheet_info)
        return len([task for task in tasks if task.task_type in ['new', 'modify', 'shorten']])

    async def _detect_translatable_sheets(
        self,
        file_path: str,
        sheet_names: List[str],
        target_languages: List[str]
    ) -> List[str]:
        """è‡ªåŠ¨æ£€æµ‹éœ€è¦ç¿»è¯‘çš„sheets"""
        translatable_sheets = []

        for sheet_name in sheet_names:
            try:
                df = pd.read_excel(file_path, sheet_name=sheet_name)

                # æ¸…ç†åˆ—å
                df.columns = [col.strip(':').strip() for col in df.columns]

                # æ£€æŸ¥æ˜¯å¦æœ‰ç›®æ ‡è¯­è¨€åˆ—ä¸”ä¸ºç©º
                has_empty_target = False
                for lang in target_languages:
                    lang_upper = lang.upper()
                    if lang_upper in [col.upper() for col in df.columns]:
                        # æ‰¾åˆ°å¯¹åº”åˆ—
                        for col in df.columns:
                            if col.upper() == lang_upper:
                                # æ£€æŸ¥æ˜¯å¦æœ‰ç©ºå€¼
                                if df[col].isna().any() or (df[col] == '').any():
                                    has_empty_target = True
                                    break

                if has_empty_target:
                    translatable_sheets.append(sheet_name)
                    logger.info(f"âœ… Sheet '{sheet_name}' éœ€è¦ç¿»è¯‘")
                else:
                    logger.info(f"â­ï¸ Sheet '{sheet_name}' è·³è¿‡ï¼ˆæ— éœ€ç¿»è¯‘ï¼‰")

            except Exception as e:
                logger.warning(f"æ£€æµ‹Sheet '{sheet_name}' å¤±è´¥: {e}")

        return translatable_sheets

    async def _save_multi_sheet_results(
        self,
        db: AsyncSession,
        task_id: str,
        all_results: Dict[str, pd.DataFrame],
        original_file_path: str
    ):
        """ä¿å­˜å¤šSheetç»“æœ"""
        try:
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            base_name = original_file_path.rsplit('.', 1)[0]
            output_path = f"{base_name}_translated_{timestamp}.xlsx"

            # ä½¿ç”¨ExcelWriterä¿å­˜å¤šä¸ªsheets
            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                for sheet_name, df in all_results.items():
                    df.to_excel(writer, sheet_name=sheet_name, index=False)

            logger.info(f"âœ… å¤šSheetç¿»è¯‘ç»“æœå·²ä¿å­˜: {output_path}")

            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            await self.project_manager.update_task_progress(
                db, task_id,
                status='completed'
            )

        except Exception as e:
            logger.error(f"ä¿å­˜å¤šSheetç»“æœå¤±è´¥: {e}")
            raise

    async def _save_and_complete_task(self, db: AsyncSession, task_id: str, df: pd.DataFrame, original_file_path: str):
        """ä¿å­˜ç»“æœå¹¶å®Œæˆä»»åŠ¡ï¼ˆå•Sheetå…¼å®¹ï¼‰"""
        try:
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å (åŸºäºDemoçš„å‘½åè§„åˆ™)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            base_name = original_file_path.rsplit('.', 1)[0]
            output_path = f"{base_name}_completed_{timestamp}.xlsx"

            # ä¿å­˜Excelæ–‡ä»¶
            df.to_excel(output_path, index=False)
            logger.info(f"ç¿»è¯‘ç»“æœå·²ä¿å­˜: {output_path}")

            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            await self.project_manager.update_task_progress(
                db, task_id,
                status='completed'
            )

        except Exception as e:
            logger.error(f"ä¿å­˜ç¿»è¯‘ç»“æœå¤±è´¥: {e}")
            raise
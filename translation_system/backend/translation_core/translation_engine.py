"""
ç¿»è¯‘å¼•æ“æ ¸å¿ƒç±»
åŸºäºtest_concurrent_batch.pyçš„å®Œæ•´æ¶æ„åŒ–å®ç°
æ”¯æŒå¤šLLMæä¾›å•†åˆ‡æ¢
"""
import asyncio
import json
import pandas as pd
import time
from datetime import datetime
from typing import List, Dict, Optional, Any
from database.connection import AsyncSession
from project_manager.manager import ProjectManager
from .placeholder_protector import PlaceholderProtector
from .localization_engine import LocalizationEngine
from .terminology_manager import TerminologyManager
from excel_analysis.header_analyzer import HeaderAnalyzer
from excel_analysis.translation_detector import TranslationDetector
from excel_analysis.enhanced_excel_reader import EnhancedExcelReader
from excel_analysis.color_task_detector import ColorTaskDetector, TaskType
from .phase_translation_manager import PhaseTranslationManager

# ä½¿ç”¨LLMé…ç½®ç®¡ç†å™¨ä½œä¸ºå”¯ä¸€æ•°æ®æº
from llm_providers import (
    LLMConfigManager,
    LLMMessage,
    ResponseFormat,
    BaseLLM
)
from config.settings import settings

import logging

logger = logging.getLogger(__name__)


class TranslationEngine:
    """ç¿»è¯‘å¼•æ“ - åŸºäºDemoçš„æ¶æ„åŒ–å®ç°"""

    def __init__(self, llm_profile: Optional[str] = None):
        """
        åˆå§‹åŒ–ç¿»è¯‘å¼•æ“

        Args:
            llm_profile: LLMé…ç½®æ–‡ä»¶åï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨active_profile
        """
        self.llm_profile = llm_profile
        self.llm_instance: Optional['BaseLLM'] = None
        self.llm_manager = LLMConfigManager()
        self.client = None  # ä¸å†ä½¿ç”¨æ—§çš„OpenAIå®¢æˆ·ç«¯

        # å…¶ä»–ç»„ä»¶
        self.project_manager = ProjectManager(None)  # OSS storage will be injected
        self.placeholder_protector = PlaceholderProtector()
        self.localization_engine = LocalizationEngine()
        self.terminology_manager = TerminologyManager()
        self.header_analyzer = HeaderAnalyzer()
        self.translation_detector = TranslationDetector()
        self.enhanced_reader = EnhancedExcelReader()  # å¢å¼ºçš„Excelè¯»å–å™¨
        self.excel_metadata = {}  # å­˜å‚¨Excelå…ƒæ•°æ®
        self.color_detector = ColorTaskDetector()  # é¢œè‰²ä»»åŠ¡æ£€æµ‹å™¨
        self.phase_manager = PhaseTranslationManager(self)  # ä¸‰é˜¶æ®µç®¡ç†å™¨

        # æœ¯è¯­ç®¡ç†ç›¸å…³
        self.current_project_id = None  # å½“å‰é¡¹ç›®ID
        self.terminology_loaded = False  # æœ¯è¯­æ˜¯å¦å·²åŠ è½½

        # ç»Ÿè®¡ä¿¡æ¯ (åŸºäºDemo)
        self.completed_batches = 0
        self.total_batches = 0
        self.failed_batches = []
        self.total_translated_rows = 0  # ç´¯è®¡ç¿»è¯‘çš„è¡Œæ•°

    async def initialize_llm(self):
        """åˆå§‹åŒ–LLMå®ä¾‹"""
        if not self.llm_instance:
            if not self.llm_profile:
                # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„active_profile
                active_profile = self.llm_manager.get_active_profile()
                if active_profile and active_profile in self.llm_manager.list_profiles():
                    self.llm_profile = active_profile
                    logger.info(f"ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ´»åŠ¨é…ç½®: {active_profile}")
                else:
                    raise ValueError("æ²¡æœ‰é…ç½®æ´»åŠ¨çš„LLM profileï¼Œè¯·åœ¨llm_configs.jsonä¸­è®¾ç½®active_profile")

            # è·å–LLMå®ä¾‹
            try:
                self.llm_instance = await self.llm_manager.get_llm(self.llm_profile)
                logger.info(f"æˆåŠŸåˆå§‹åŒ–LLM: {self.llm_instance.get_provider_name()} - {self.llm_profile}")
            except Exception as e:
                logger.error(f"åˆå§‹åŒ–LLMå¤±è´¥ ({self.llm_profile}): {e}")
                # å¦‚æœå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨å¤‡ç”¨é…ç½®
                if self.llm_profile != "qwen-plus" and "qwen-plus" in self.llm_manager.list_profiles():
                    logger.info("å°è¯•ä½¿ç”¨å¤‡ç”¨é…ç½®: qwen-plus")
                    self.llm_profile = "qwen-plus"
                    self.llm_instance = await self.llm_manager.get_llm(self.llm_profile)
                    logger.info(f"ä½¿ç”¨å¤‡ç”¨é…ç½®æˆåŠŸ: {self.llm_instance.get_provider_name()}")
                else:
                    raise

    async def switch_llm(self, profile_name: str):
        """
        åˆ‡æ¢LLMé…ç½®

        Args:
            profile_name: æ–°çš„é…ç½®æ–‡ä»¶å
        """
        if profile_name not in self.llm_manager.list_profiles():
            raise ValueError(f"Profile {profile_name} not found")

        self.llm_profile = profile_name
        self.llm_instance = await self.llm_manager.get_llm(profile_name)
        logger.info(f"Switched to LLM: {self.llm_instance.get_provider_name()} - {profile_name}")

    def get_available_profiles(self) -> List[str]:
        """è·å–å¯ç”¨çš„LLMé…ç½®æ–‡ä»¶åˆ—è¡¨"""
        if self.llm_manager:
            return self.llm_manager.list_profiles()
        return []

    def get_model_info(self) -> Dict[str, Any]:
        """è·å–å½“å‰æ¨¡å‹ä¿¡æ¯"""
        if self.llm_instance:
            return self.llm_instance.get_model_info()
        return {}

    async def process_translation_task(
        self,
        db: AsyncSession,
        task_id: str,
        file_path: str,
        target_languages: List[str] = None,  # None = è‡ªåŠ¨æ£€æµ‹æ‰€æœ‰éœ€è¦çš„è¯­è¨€
        batch_size: int = 3,
        max_concurrent: int = 10,
        max_iterations: int = 5,
        region_code: str = 'na',
        game_background: str = None,
        sheet_names: List[str] = None,  # None = å¤„ç†æ‰€æœ‰sheets
        auto_detect: bool = True,  # è‡ªåŠ¨æ£€æµ‹éœ€è¦ç¿»è¯‘çš„sheets
        project_id: Optional[str] = None  # é¡¹ç›®IDï¼Œç”¨äºæœ¯è¯­ç®¡ç†
    ):
        """å¤„ç†ç¿»è¯‘ä»»åŠ¡ - æ”¯æŒå¤šSheetå¤„ç†"""
        try:
            # åˆå§‹åŒ–LLM
            await self.initialize_llm()

            # æ‰“å°æ¨¡å‹ä¿¡æ¯
            if self.llm_instance:
                model_info = self.llm_instance.get_model_info()
                logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œç¿»è¯‘ä»»åŠ¡: {task_id}")
                logger.info(f"ğŸ¤– å½“å‰ä½¿ç”¨æ¨¡å‹: {model_info.get('provider', 'Unknown')} - {model_info.get('model', 'Unknown')}")
                logger.info(f"ğŸ“ æ¨¡å‹è¯¦æƒ…: {model_info.get('model_name', 'Unknown')}")
                logger.info(f"âš¡ é…ç½®æ–‡ä»¶: {self.llm_profile or 'active_profile'}")
            else:
                logger.error(f"âŒ æ— æ³•åˆå§‹åŒ–LLMï¼Œè¯·æ£€æŸ¥é…ç½®")
                raise RuntimeError("LLM initialization failed")

            # é¢„åŠ è½½æœ¯è¯­è¡¨ï¼ˆå¦‚æœå¯ç”¨ä¸”æä¾›äº†project_idï¼‰
            if settings.terminology_enabled and project_id:
                self.current_project_id = project_id
                try:
                    await self.terminology_manager.preload_all_terminology(db, project_id)
                    self.terminology_loaded = True
                    logger.info(f"âœ… æœ¯è¯­è¡¨é¢„åŠ è½½æˆåŠŸ: {project_id}")
                except Exception as e:
                    logger.warning(f"âš ï¸ æœ¯è¯­è¡¨é¢„åŠ è½½å¤±è´¥: {e}ï¼Œç»§ç»­ç¿»è¯‘ä½†ä¸ä½¿ç”¨æœ¯è¯­")
                    self.terminology_loaded = False
            elif not settings.terminology_enabled:
                logger.info("æœ¯è¯­ç³»ç»Ÿå·²ç¦ç”¨ï¼ˆé€šè¿‡é…ç½®ï¼‰")

            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            await self.project_manager.update_task_progress(
                db, task_id, status='analyzing'
            )

            # 1. åˆ†æExcelæ–‡ä»¶ç»“æ„
            xl_file = pd.ExcelFile(file_path)
            all_sheet_names = xl_file.sheet_names
            logger.info(f"Excelæ–‡ä»¶åŒ…å« {len(all_sheet_names)} ä¸ªSheet: {all_sheet_names}")

            # 2. ç¡®å®šè¦å¤„ç†çš„sheets
            if sheet_names:
                sheets_to_process = [s for s in sheet_names if s in all_sheet_names]
            else:
                sheets_to_process = all_sheet_names

            # 3. è‡ªåŠ¨æ£€æµ‹éœ€è¦ç¿»è¯‘çš„sheets
            # æ³¨æ„ï¼šç°åœ¨ä¸ä¾èµ–target_languagesï¼Œè®©TranslationDetectorè‡ªåŠ¨æ£€æµ‹æ‰€æœ‰éœ€è¦ç¿»è¯‘çš„å†…å®¹
            if auto_detect:
                sheets_to_process = await self._detect_sheets_with_content(
                    file_path, sheets_to_process
                )

            logger.info(f"å°†å¤„ç† {len(sheets_to_process)}/{len(all_sheet_names)} ä¸ªSheets: {sheets_to_process}")

            if not sheets_to_process:
                logger.info("æ²¡æœ‰éœ€è¦ç¿»è¯‘çš„Sheet")
                await self.project_manager.update_task_progress(
                    db, task_id, status='completed'
                )
                return

            # 4. å­˜å‚¨æ‰€æœ‰Sheetçš„ç»“æœ
            all_results = {}
            total_translated = 0
            self.total_translated_rows = 0  # é‡ç½®ç´¯è®¡ç¿»è¯‘è¡Œæ•°

            # åˆå§‹åŒ–Sheetè¿›åº¦å­—å…¸
            sheet_progress = {}
            for sheet in sheets_to_process:
                sheet_progress[sheet] = {
                    'total_rows': len(pd.read_excel(file_path, sheet_name=sheet)),
                    'translated_rows': 0,
                    'status': 'pending'
                }

            # 5. é€ä¸ªå¤„ç†æ¯ä¸ªSheet
            for sheet_idx, sheet_name in enumerate(sheets_to_process, 1):
                logger.info(f"\n{'='*50}")
                logger.info(f"å¤„ç†Sheet {sheet_idx}/{len(sheets_to_process)}: {sheet_name}")
                logger.info(f"{'='*50}")

                # ä½¿ç”¨å¢å¼ºè¯»å–å™¨åŠ è½½å½“å‰Sheetï¼ˆåŒ…å«å…ƒæ•°æ®ï¼‰
                try:
                    df, sheet_metadata = self.enhanced_reader.read_excel_with_metadata(file_path, sheet_name)

                    # å­˜å‚¨å…ƒæ•°æ®ä¾›åç»­ä½¿ç”¨
                    if sheet_metadata:
                        self.excel_metadata[sheet_name] = sheet_metadata.get(sheet_name, {})

                        # æå–æ‰¹æ³¨ä½œä¸ºç¿»è¯‘ä¸Šä¸‹æ–‡
                        comments = self.enhanced_reader.extract_comments_as_context(
                            self.excel_metadata[sheet_name]
                        )
                        if comments:
                            logger.info(f"å‘ç° {len(comments)} ä¸ªæ‰¹æ³¨ï¼Œå°†ä½œä¸ºç¿»è¯‘å‚è€ƒ")

                        # æå–å¸¦é¢œè‰²çš„å•å…ƒæ ¼
                        colored_cells = self.enhanced_reader.get_colored_cells(
                            self.excel_metadata[sheet_name]
                        )
                        if colored_cells:
                            logger.info(f"å‘ç° {len(colored_cells)} ä¸ªå¸¦é¢œè‰²çš„å•å…ƒæ ¼")

                    logger.info(f"Sheet '{sheet_name}' åŠ è½½æˆåŠŸï¼ˆå«å…ƒæ•°æ®ï¼‰ï¼Œæ€»è¡Œæ•°: {len(df)}")

                except Exception as e:
                    logger.warning(f"å¢å¼ºè¯»å–å¤±è´¥ï¼Œé™çº§åˆ°æ™®é€šè¯»å–: {e}")
                    df = pd.read_excel(file_path, sheet_name=sheet_name)
                    logger.info(f"Sheet '{sheet_name}' åŠ è½½æˆåŠŸï¼ˆæ™®é€šæ¨¡å¼ï¼‰ï¼Œæ€»è¡Œæ•°: {len(df)}")

                # æ¸…ç†åˆ—åï¼ˆå»é™¤ç‰¹æ®Šå­—ç¬¦å¦‚å†’å·ï¼‰
                df.columns = [col.strip(':').strip() for col in df.columns]

                # åŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°ï¼ˆå¤§æ–‡ä»¶ä¼˜åŒ–ï¼‰
                if len(df) > 5000:
                    current_batch_size = min(30, batch_size * 3)  # æœ€å¤§30è¡Œ
                    logger.info(f"å¤§æ–‡ä»¶ä¼˜åŒ–ï¼šæ‰¹æ¬¡å¤§å°è°ƒæ•´ä¸º {current_batch_size}")
                elif len(df) > 1000:
                    current_batch_size = min(20, batch_size * 2)  # ä¸­ç­‰æ–‡ä»¶20è¡Œ
                    logger.info(f"ä¸­ç­‰æ–‡ä»¶ä¼˜åŒ–ï¼šæ‰¹æ¬¡å¤§å°è°ƒæ•´ä¸º {current_batch_size}")
                else:
                    current_batch_size = min(10, batch_size)  # å°æ–‡ä»¶10è¡Œ

                # 2. æ™ºèƒ½åˆ†æè¡¨å¤´ç»“æ„
                sheet_info = self.header_analyzer.analyze_sheet(df, sheet_name)
                logger.info(f"è¡¨å¤´åˆ†æå®Œæˆï¼Œå¯ç¿»è¯‘è¡Œæ•°: {sheet_info.translatable_rows}")

                # 3. åˆå§‹ä»»åŠ¡æ£€æµ‹
                initial_tasks = self.translation_detector.detect_translation_tasks(df, sheet_info)
                logger.info(f"åˆå§‹æ£€æµ‹åˆ°ç¿»è¯‘ä»»åŠ¡: {len(initial_tasks)}ä¸ª")

                if not initial_tasks:
                    logger.info(f"Sheet '{sheet_name}' æ²¡æœ‰éœ€è¦ç¿»è¯‘çš„å†…å®¹")
                    all_results[sheet_name] = df
                    continue

                await self.project_manager.update_task_progress(
                    db, task_id,
                    status='translating',
                    current_sheet=sheet_name
                )

                # è®°å½•å½“å‰Sheetçš„åˆå§‹è¡Œæ•°
                sheet_total_rows = len(df)
                sheet_translated_rows = 0
                sheet_progress[sheet_name]['status'] = 'translating'

                # 4. è¿­ä»£ç¿»è¯‘ - çœŸæ­£çš„å¢é‡å¤„ç†
                current_df = df.copy()
                iteration = 0
                failed_batch_count = 0

                # åŠ¨æ€è°ƒæ•´å‚æ•°
                dynamic_batch_size = current_batch_size
                dynamic_timeout = 90  # åˆå§‹è¶…æ—¶90ç§’

                while iteration < max_iterations:
                    iteration += 1

                    # æ¯è½®é‡æ–°æ£€æµ‹å‰©ä½™ä»»åŠ¡ - å…³é”®æ”¹è¿›ï¼
                    remaining_tasks = self.translation_detector.detect_translation_tasks(current_df, sheet_info)

                    if not remaining_tasks:
                        logger.info(f"Sheet '{sheet_name}' - ç¬¬{iteration}è½®è¿­ä»£ï¼šæ‰€æœ‰ä»»åŠ¡å·²å®Œæˆ")
                        break

                    logger.info(f"Sheet '{sheet_name}' - ç¬¬{iteration}è½®è¿­ä»£ï¼šæ£€æµ‹åˆ° {len(remaining_tasks)} ä¸ªå‰©ä½™ä»»åŠ¡")

                    # æ ¹æ®è¿­ä»£æ¬¡æ•°å’Œå¤±è´¥æƒ…å†µåŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°
                    if iteration > 1 and failed_batch_count > 0:
                        # æœ‰å¤±è´¥ï¼Œå‡å°æ‰¹æ¬¡å¤§å°
                        dynamic_batch_size = max(1, dynamic_batch_size // 2)
                        # å¢åŠ è¶…æ—¶æ—¶é—´
                        dynamic_timeout = min(300, dynamic_timeout * 1.5)  # å¢åŠ æœ€å¤§è¶…æ—¶åˆ°300ç§’
                        logger.info(f"è°ƒæ•´ç­–ç•¥ï¼šæ‰¹æ¬¡å¤§å°={dynamic_batch_size}ï¼Œè¶…æ—¶={dynamic_timeout}ç§’")

                    # æ£€æµ‹é•¿æ–‡æœ¬ä»»åŠ¡ï¼Œè¿›ä¸€æ­¥è°ƒæ•´
                    max_text_length = max([len(task.source_text) for task in remaining_tasks] or [0])
                    if max_text_length > 300:  # é™ä½é˜ˆå€¼ï¼Œæ›´æ—©ä¼˜åŒ–
                        dynamic_batch_size = min(dynamic_batch_size, 3)  # æœ€å¤š3ä¸ªä»»åŠ¡ä¸€æ‰¹
                        dynamic_timeout = max(dynamic_timeout, 180)  # è‡³å°‘180ç§’è¶…æ—¶
                        if max_text_length > 500:  # é•¿æ–‡æœ¬
                            dynamic_batch_size = min(dynamic_batch_size, 2)  # æœ€å¤š2ä¸ªä»»åŠ¡ä¸€æ‰¹
                            dynamic_timeout = max(dynamic_timeout, 240)  # 4åˆ†é’Ÿè¶…æ—¶
                        if max_text_length > 800:  # è¶…é•¿æ–‡æœ¬ï¼ˆå¦‚909å­—ç¬¦ï¼‰
                            dynamic_batch_size = 1  # å•ä¸ªä»»åŠ¡ä¸€æ‰¹
                            dynamic_timeout = 360  # 6åˆ†é’Ÿè¶…æ—¶
                        logger.info(f"æ£€æµ‹åˆ°é•¿æ–‡æœ¬(æœ€é•¿{max_text_length}å­—ç¬¦)ï¼Œè°ƒæ•´æ‰¹æ¬¡å¤§å°={dynamic_batch_size}ï¼Œè¶…æ—¶={dynamic_timeout}ç§’")

                    # åˆ›å»ºæ–°æ‰¹æ¬¡
                    batches = self.translation_detector.group_tasks_by_batch(remaining_tasks, dynamic_batch_size)
                    self.total_batches = len(batches)
                    self.completed_batches = 0
                    self.failed_batches = []

                    logger.info(f"Sheet '{sheet_name}' - ç¬¬{iteration}è½®è¿­ä»£ï¼šåˆ›å»º {len(batches)} ä¸ªæ‰¹æ¬¡")

                    # æ›´æ–°è¿­ä»£çŠ¶æ€
                    status = 'iterating' if iteration > 1 else 'translating'
                    await self.project_manager.update_task_progress(
                        db, task_id,
                        current_iteration=iteration,
                        status=status
                    )

                    # å¹¶å‘å¤„ç†æ‰¹æ¬¡ï¼ˆä¼ å…¥åŠ¨æ€è¶…æ—¶å‚æ•°å’ŒSheetä¿¡æ¯ï¼‰
                    semaphore = asyncio.Semaphore(max_concurrent)
                    translation_results = await self._process_batches_concurrent_with_timeout(
                        db, task_id, batches, target_languages, semaphore,
                        region_code, game_background, iteration, dynamic_timeout,
                        sheet_name, sheet_progress
                    )

                    # è®°å½•å¤±è´¥æ‰¹æ¬¡æ•°
                    failed_batch_count = len(self.failed_batches)
                    if failed_batch_count > 0:
                        logger.warning(f"ç¬¬{iteration}è½®æœ‰ {failed_batch_count} ä¸ªæ‰¹æ¬¡å¤±è´¥")

                    # åº”ç”¨ç¿»è¯‘ç»“æœåˆ°DataFrame
                    translated_count = self._apply_translation_results(current_df, translation_results)
                    total_translated += translated_count

                    # æ›´æ–°è¿›åº¦
                    await self.project_manager.update_task_progress(
                        db, task_id,
                        translated_rows=total_translated
                    )

                    # æ£€æŸ¥å‰©ä½™ä»»åŠ¡æ•°
                    final_remaining = self._count_remaining_tasks(current_df, sheet_info)
                    logger.info(f"Sheet '{sheet_name}' - ç¬¬{iteration}è½®è¿­ä»£å®Œæˆï¼Œå‰©ä½™ä»»åŠ¡: {final_remaining}")

                # ä¿å­˜å½“å‰Sheetç»“æœ
                all_results[sheet_name] = current_df

            # 6. ä¿å­˜æ‰€æœ‰Sheetç»“æœå¹¶å®Œæˆä»»åŠ¡
            await self._save_multi_sheet_results(db, task_id, all_results, file_path)

        except Exception as e:
            logger.error(f"ç¿»è¯‘ä»»åŠ¡å¤„ç†å¤±è´¥: {task_id}, é”™è¯¯: {e}")
            await self.project_manager.update_task_progress(
                db, task_id,
                status='failed',
                error_message=str(e)
            )
            raise

    async def _process_batches_concurrent(
        self,
        db: AsyncSession,
        task_id: str,
        batches: List[List],
        target_languages: List[str],
        semaphore: asyncio.Semaphore,
        region_code: str,
        game_background: str,
        iteration: int
    ) -> Dict:
        """å¹¶å‘å¤„ç†æ‰¹æ¬¡ - åŸºäºDemoçš„å¹¶å‘é€»è¾‘"""
        # ä¿ç•™åŸæ–¹æ³•ç”¨äºå…¼å®¹æ€§ï¼Œè°ƒç”¨æ–°æ–¹æ³•withé»˜è®¤è¶…æ—¶
        return await self._process_batches_concurrent_with_timeout(
            db, task_id, batches, target_languages, semaphore,
            region_code, game_background, iteration, 90
        )

    async def _process_batches_concurrent_with_timeout(
        self,
        db: AsyncSession,
        task_id: str,
        batches: List[List],
        target_languages: List[str],
        semaphore: asyncio.Semaphore,
        region_code: str,
        game_background: str,
        iteration: int,
        timeout: int,
        sheet_name: str = None,
        sheet_progress: dict = None
    ) -> Dict:
        """å¹¶å‘å¤„ç†æ‰¹æ¬¡ - æ”¯æŒåŠ¨æ€è¶…æ—¶"""
        tasks = []

        for batch_id, batch in enumerate(batches, 1):
            task = self._translate_batch_with_retry(
                db, task_id, batch, batch_id, target_languages,
                semaphore, region_code, game_background, iteration,
                timeout=timeout, sheet_name=sheet_name, sheet_progress=sheet_progress
            )
            tasks.append(task)

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰æ‰¹æ¬¡
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # åˆå¹¶ç»“æœ
        translation_results = {}
        for result in results:
            if isinstance(result, dict):
                translation_results.update(result)
            else:
                logger.error(f"æ‰¹æ¬¡å¤„ç†å¤±è´¥: {result}")

        return translation_results

    async def _translate_batch_with_retry(
        self,
        db: AsyncSession,
        task_id: str,
        batch: List,
        batch_id: int,
        target_languages: List[str],
        semaphore: asyncio.Semaphore,
        region_code: str,
        game_background: str,
        iteration: int,
        max_retry_attempts: int = 2,
        retry_base_delay: float = 3.0,
        timeout: int = 90,  # æ”¯æŒåŠ¨æ€è¶…æ—¶
        sheet_name: str = None,
        sheet_progress: dict = None
    ) -> Dict:
        """æ‰¹æ¬¡ç¿»è¯‘å¸¦é‡è¯•æœºåˆ¶ - æ”¯æŒåŠ¨æ€è¶…æ—¶å’Œæ™ºèƒ½é‡è¯•"""
        async with semaphore:
            start_time = time.time()

            # æ£€æµ‹æ‰¹æ¬¡ä¸­çš„æœ€é•¿æ–‡æœ¬
            max_length = max([len(task.source_text) for task in batch] or [0])

            # åŠ¨æ€è°ƒæ•´é‡è¯•å‚æ•°
            if max_length > 1000:
                max_retry_attempts = 3  # é•¿æ–‡æœ¬å¢åŠ é‡è¯•æ¬¡æ•°
                retry_base_delay = 5.0  # å¢åŠ åŸºç¡€å»¶è¿Ÿ
                logger.info(f"ğŸ“¦ æ‰¹æ¬¡{batch_id}: å¤„ç† {len(batch)}ä¸ªä»»åŠ¡ (æœ€é•¿{max_length}å­—ç¬¦, è¶…æ—¶: {timeout}ç§’, æœ€å¤šé‡è¯•{max_retry_attempts}æ¬¡)")
            else:
                logger.info(f"ğŸ“¦ æ‰¹æ¬¡{batch_id}: å¼€å§‹å¤„ç† {len(batch)}ä¸ªä»»åŠ¡ (è¶…æ—¶: {timeout}ç§’)")

            # å‡†å¤‡è¾“å…¥æ•°æ® - æ·»åŠ å ä½ç¬¦ä¿æŠ¤
            input_texts = []
            protected_texts = {}  # ä¿å­˜å ä½ç¬¦æ˜ å°„

            for i, task in enumerate(batch):
                # ä¿æŠ¤å ä½ç¬¦
                protected_text, placeholders = self.placeholder_protector.protect_placeholders(task.source_text)
                protected_texts[f"batch_{batch_id}_text_{i}"] = placeholders

                input_texts.append({
                    "id": f"batch_{batch_id}_text_{i}",
                    "text": protected_text
                })

            # é‡è¯•æœºåˆ¶ - å¢å¼ºç‰ˆ
            for attempt in range(max_retry_attempts + 1):
                try:
                    if attempt > 0:
                        retry_delay = retry_base_delay * (2 ** (attempt - 1))
                        # æ¯æ¬¡é‡è¯•å¢åŠ è¶…æ—¶æ—¶é—´
                        current_timeout = min(timeout * (1 + attempt * 0.5), 600)  # æœ€å¤š10åˆ†é’Ÿ
                        logger.info(f"ğŸ”„ æ‰¹æ¬¡{batch_id}: ç¬¬{attempt + 1}æ¬¡å°è¯•ï¼Œå»¶è¿Ÿ{retry_delay:.1f}sï¼Œè¶…æ—¶{current_timeout:.0f}s")
                        await asyncio.sleep(retry_delay)
                    else:
                        current_timeout = timeout

                    # ä»æ‰¹æ¬¡ä¸­æå–ç›®æ ‡è¯­è¨€ï¼ˆæ¯ä¸ªä»»åŠ¡éƒ½çŸ¥é“è‡ªå·±çš„ç›®æ ‡è¯­è¨€ï¼‰
                    batch_target_languages = list(set([task.target_language for task in batch]))

                    # å¦‚æœåŒºåŸŸä»£ç æ˜¯'auto'ï¼Œæ ¹æ®è¯­è¨€è‡ªåŠ¨é€‰æ‹©
                    actual_region_code = region_code
                    if region_code == 'auto' and batch_target_languages:
                        # ä½¿ç”¨ç¬¬ä¸€ä¸ªç›®æ ‡è¯­è¨€æ¥ç¡®å®šåŒºåŸŸ
                        actual_region_code = self.localization_engine.get_region_for_language(batch_target_languages[0])
                        logger.debug(f"è‡ªåŠ¨é€‰æ‹©åŒºåŸŸ: {batch_target_languages[0]} -> {actual_region_code}")

                    # æå–æ‰¹æ¬¡çš„æ‰¹æ³¨ä¿¡æ¯
                    batch_comments = {}
                    for idx, task in enumerate(batch):
                        # è·å–æºå•å…ƒæ ¼åœ°å€
                        source_cell_addr = self._get_cell_address_from_task(task)
                        # æŸ¥æ‰¾æ‰¹æ³¨
                        if source_cell_addr and sheet_name in self.excel_metadata:
                            sheet_metadata = self.excel_metadata[sheet_name]
                            if source_cell_addr in sheet_metadata:
                                cell_meta = sheet_metadata[source_cell_addr]
                                if cell_meta.comment:
                                    batch_comments[f"text_{idx}"] = cell_meta.comment

                    # æœ¯è¯­åŒ¹é…ï¼ˆå¦‚æœå¯ç”¨ä¸”å·²åŠ è½½æœ¯è¯­ï¼‰
                    matched_terms = {}
                    terminology_text = ""
                    if settings.terminology_enabled and self.terminology_loaded and self.current_project_id:
                        batch_texts = [task.source_text for task in batch]
                        matched_terms = self.terminology_manager.match_terminology_for_batch(
                            batch_texts,
                            self.current_project_id,
                            batch_target_languages if batch_target_languages else ['en']
                        )

                        # æ ¼å¼åŒ–æœ¯è¯­ç”¨äºprompt
                        if matched_terms:
                            terminology_text = self.terminology_manager.format_terminology_for_prompt(
                                matched_terms,
                                batch_target_languages if batch_target_languages else ['en']
                            )
                            logger.debug(f"æ‰¹æ¬¡{batch_id}: åŒ¹é…åˆ°{len(matched_terms)}ä¸ªæœ¯è¯­")

                            # æ£€æŸ¥æ˜¯å¦å¯ä»¥ä½¿ç”¨ç›´æ¥æ›¿æ¢ç­–ç•¥ï¼ˆå¦‚æœé…ç½®å…è®¸ï¼‰
                            if settings.terminology_direct_replace_enabled:
                                can_direct_replace = self._check_direct_replace_strategy(batch_texts, matched_terms)
                            else:
                                can_direct_replace = False

                            # å¦‚æœå¯ä»¥ç›´æ¥æ›¿æ¢ï¼Œè·³è¿‡LLMè°ƒç”¨
                            if can_direct_replace:
                                batch_results = self._apply_direct_replacement(
                                    batch,
                                    matched_terms,
                                    batch_target_languages if batch_target_languages else ['en']
                                )

                                # è®°å½•ç»Ÿè®¡ä¿¡æ¯
                                self.completed_batches += 1
                                self.total_translated_rows += len(batch)

                                end_time = time.time()
                                logger.info(f"âœ… æ‰¹æ¬¡{batch_id}: ç›´æ¥æ›¿æ¢å®Œæˆï¼Œè€—æ—¶ {end_time - start_time:.1f}ç§’")

                                return batch_results

                    # åˆ›å»ºåŒºåŸŸåŒ–æç¤ºè¯ (å‡çº§Demoçš„é€šç”¨æç¤ºè¯ï¼Œå¸¦æ‰¹æ³¨å’Œæœ¯è¯­)
                    system_prompt = self.localization_engine.create_batch_prompt(
                        [task.source_text for task in batch],
                        batch_target_languages if batch_target_languages else ['en'],  # é»˜è®¤è‹±è¯­
                        actual_region_code,
                        game_background,
                        batch[0].task_type if batch else 'new',
                        cell_comments=batch_comments,  # ä¼ é€’æ‰¹æ³¨ä¿¡æ¯
                        terminology=matched_terms  # ä¼ é€’åŒ¹é…çš„æœ¯è¯­
                    )

                    # æ„å»ºè¯·æ±‚æ¶ˆæ¯
                    user_message = f"è¯·ç¿»è¯‘ä»¥ä¸‹ä¸­æ–‡æ–‡æœ¬ï¼š\n{json.dumps(input_texts, ensure_ascii=False, indent=2)}"

                    # è°ƒç”¨LLM
                    if self.llm_instance:
                        # ä½¿ç”¨LLM Provider
                        model_info = self.llm_instance.get_model_info()
                        if batch_id == 1 and attempt == 0:  # åªåœ¨ç¬¬ä¸€ä¸ªæ‰¹æ¬¡çš„ç¬¬ä¸€æ¬¡å°è¯•æ—¶æ‰“å°
                            logger.info(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_info.get('provider', 'Unknown')} - {model_info.get('model', 'Unknown')} ({model_info.get('model_name', 'Unknown')})")
                            logger.info(f"ğŸ› ï¸  é…ç½®: æ¸©åº¦={0.3}, æœ€å¤§tokens={4000}, åŒºåŸŸ={actual_region_code}")

                        llm_messages = [
                            LLMMessage(role="system", content=system_prompt),
                            LLMMessage(role="user", content=user_message)
                        ]

                        # ä½¿ç”¨é…ç½®çš„max_tokenså€¼ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
                        max_tokens = self.llm_instance.config.max_tokens if hasattr(self.llm_instance, 'config') else 8000

                        response = await self.llm_instance.chat_completion(
                            messages=llm_messages,
                            temperature=0.3,
                            max_tokens=max_tokens,
                            response_format=ResponseFormat.JSON,
                            timeout=current_timeout
                        )

                        # å¤„ç†å“åº”
                        result = json.loads(response.content)
                        translations = result.get("translations", [])

                        # è®°å½•tokenä½¿ç”¨
                        tokens_used = response.usage.get("total_tokens", 0) if response.usage else 0
                    else:
                        # LLMæœªåˆå§‹åŒ–
                        raise RuntimeError("LLM instance not initialized")

                    # è¿˜åŸå ä½ç¬¦
                    for translation_item in translations:
                        if "id" in translation_item and translation_item["id"] in protected_texts:
                            placeholders = protected_texts[translation_item["id"]]
                            # è¿˜åŸæ‰€æœ‰è¯­è¨€çš„ç¿»è¯‘ç»“æœ
                            for lang_key in translation_item:
                                if lang_key != "id" and translation_item[lang_key]:
                                    translation_item[lang_key] = self.placeholder_protector.restore_placeholders(
                                        translation_item[lang_key], placeholders
                                    )

                    # è®°å½•APIç»Ÿè®¡
                    api_calls = 1

                    # æ¯ä¸ªæ‰¹æ¬¡éƒ½æ›´æ–°è¿›åº¦ï¼Œè®©ç”¨æˆ·èƒ½å®æ—¶çœ‹åˆ°è¿›åº¦å˜åŒ–
                    try:
                        # æ›´æ–°APIè°ƒç”¨ç»Ÿè®¡ï¼ˆç´¯åŠ ï¼‰
                        await self.project_manager.update_task_progress(
                            db, task_id,
                            api_calls=api_calls,
                            tokens_used=tokens_used
                        )
                    except Exception as update_error:
                        logger.warning(f"æ›´æ–°è¿›åº¦å¤±è´¥: {update_error}")

                    # æ„å»ºè¿”å›ç»“æœ
                    batch_results = {}
                    for i, translation in enumerate(translations):
                        if i < len(batch):
                            task = batch[i]
                            # ä½¿ç”¨ä»»åŠ¡è‡ªå·±çš„ç›®æ ‡è¯­è¨€
                            batch_results[task.row_index] = {
                                task.target_language: translation.get(task.target_language, translation) if isinstance(translation, dict) else translation
                            }

                    elapsed = time.time() - start_time
                    self.completed_batches += 1

                    # è®¡ç®—æ‰¹æ¬¡ä¸­çš„å”¯ä¸€è¡Œæ•°ï¼ˆåŒä¸€è¡Œçš„å¤šä¸ªä»»åŠ¡ç®—ä¸€è¡Œï¼‰
                    unique_rows_in_batch = len(set(task.row_index for task in batch))
                    self.total_translated_rows += unique_rows_in_batch

                    # å¦‚æœæœ‰Sheetä¿¡æ¯ï¼Œæ›´æ–°Sheetçº§åˆ«çš„è¿›åº¦
                    if sheet_name and sheet_progress:
                        sheet_progress[sheet_name]['translated_rows'] += unique_rows_in_batch

                    # å®æ—¶æ›´æ–°ç¿»è¯‘è¡Œæ•°è¿›åº¦ï¼ˆåŒ…æ‹¬Sheetè¿›åº¦ï¼‰
                    try:
                        await self.project_manager.update_task_progress(
                            db, task_id,
                            translated_rows=self.total_translated_rows,
                            sheet_progress=sheet_progress if sheet_progress else None
                        )
                    except Exception as update_error:
                        logger.warning(f"æ›´æ–°è¡Œæ•°è¿›åº¦å¤±è´¥: {update_error}")

                    retry_info = f" (ç¬¬{attempt + 1}æ¬¡å°è¯•)" if attempt > 0 else ""
                    logger.info(f"âœ… æ‰¹æ¬¡{batch_id}: å®Œæˆç¿»è¯‘{retry_info} {len(translations)}æ¡ | "
                              f"è€—æ—¶{elapsed:.1f}s | tokens: {tokens_used} | "
                              f"è¿›åº¦: {self.completed_batches}/{self.total_batches}")

                    return batch_results

                except Exception as e:
                    elapsed = time.time() - start_time

                    if attempt < max_retry_attempts:
                        logger.warning(f"âš ï¸ æ‰¹æ¬¡{batch_id}: ç¬¬{attempt + 1}æ¬¡å°è¯•å¤±è´¥ | é”™è¯¯: {e}")
                    else:
                        logger.error(f"âŒ æ‰¹æ¬¡{batch_id}: é‡è¯•{max_retry_attempts}æ¬¡åæœ€ç»ˆå¤±è´¥ | æ€»è€—æ—¶{elapsed:.1f}s | é”™è¯¯: {e}")
                        self.failed_batches.append(batch_id)

            return {}  # å¤±è´¥æ—¶è¿”å›ç©ºç»“æœ

    def _apply_translation_results(self, df: pd.DataFrame, results: Dict) -> int:
        """åº”ç”¨ç¿»è¯‘ç»“æœåˆ°DataFrame"""
        translated_count = 0

        for row_index, translations in results.items():
            for lang, translation in translations.items():
                if translation and translation.strip():
                    # æ‰¾åˆ°å¯¹åº”çš„è¯­è¨€åˆ— - æ›´ç²¾ç¡®çš„åŒ¹é…
                    lang_upper = lang.upper()
                    matched_col = None

                    # é¦–å…ˆå°è¯•ç²¾ç¡®åŒ¹é…
                    if lang_upper in df.columns:
                        matched_col = lang_upper
                    # å…¶æ¬¡å°è¯•å°å†™åŒ¹é…
                    elif lang.lower() in [col.lower() for col in df.columns]:
                        for col in df.columns:
                            if col.lower() == lang.lower():
                                matched_col = col
                                break

                    # å¦‚æœåˆ—ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°åˆ—
                    if not matched_col:
                        matched_col = lang_upper
                        if matched_col not in df.columns:
                            df[matched_col] = ''
                            logger.info(f"åˆ›å»ºæ–°è¯­è¨€åˆ—: {matched_col}")

                    # åº”ç”¨ç¿»è¯‘
                    if matched_col:
                        df.at[row_index, matched_col] = translation
                        translated_count += 1
                        logger.debug(f"åº”ç”¨ç¿»è¯‘: è¡Œ{row_index}, åˆ—{matched_col} = {translation[:30]}...")

        return translated_count

    def _get_cell_address_from_task(self, task) -> Optional[str]:
        """ä»ä»»åŠ¡è·å–å•å…ƒæ ¼åœ°å€"""
        if hasattr(task, 'row_index') and hasattr(task, 'source_column'):
            # ç®€å•å®ç°ï¼šå‡è®¾åˆ—ç´¢å¼•
            col_letter = 'B'  # é€šå¸¸ä¸­æ–‡åœ¨Båˆ—
            row_num = task.row_index + 2  # +2å› ä¸ºæœ‰æ ‡é¢˜è¡Œä¸”Excelä»1å¼€å§‹
            return f"{col_letter}{row_num}"
        return None

    def _count_remaining_tasks(self, df: pd.DataFrame, sheet_info) -> int:
        """ç»Ÿè®¡å‰©ä½™ç¿»è¯‘ä»»åŠ¡æ•°é‡"""
        tasks = self.translation_detector.detect_translation_tasks(df, sheet_info)
        return len([task for task in tasks if task.task_type in ['new', 'modify', 'shorten']])

    async def _detect_sheets_with_content(
        self,
        file_path: str,
        sheet_names: List[str]
    ) -> List[str]:
        """æ£€æµ‹å“ªäº›sheetsæœ‰å†…å®¹éœ€è¦ç¿»è¯‘ï¼ˆä¸ä¾èµ–target_languagesï¼‰"""
        translatable_sheets = []

        for sheet_name in sheet_names:
            try:
                df = pd.read_excel(file_path, sheet_name=sheet_name)
                # æ¸…ç†åˆ—å
                df.columns = [col.strip(':').strip() for col in df.columns]

                # ä½¿ç”¨HeaderAnalyzerå’ŒTranslationDetectoræ£€æµ‹
                sheet_info = self.header_analyzer.analyze_sheet(df, sheet_name)
                tasks = self.translation_detector.detect_translation_tasks(df, sheet_info)

                if tasks:
                    translatable_sheets.append(sheet_name)
                    logger.info(f"âœ… Sheet '{sheet_name}' éœ€è¦ç¿»è¯‘ ({len(tasks)} ä¸ªä»»åŠ¡)")
                else:
                    logger.info(f"â­ï¸ Sheet '{sheet_name}' è·³è¿‡ï¼ˆæ— éœ€ç¿»è¯‘ï¼‰")

            except Exception as e:
                logger.warning(f"æ£€æµ‹Sheet '{sheet_name}' å¤±è´¥: {e}")

        return translatable_sheets


    async def _save_multi_sheet_results(
        self,
        db: AsyncSession,
        task_id: str,
        all_results: Dict[str, pd.DataFrame],
        original_file_path: str
    ):
        """ä¿å­˜å¤šSheetç»“æœ"""
        try:
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            base_name = original_file_path.rsplit('.', 1)[0]
            output_path = f"{base_name}_translated_{timestamp}.xlsx"

            # æ£€æŸ¥æ˜¯å¦æœ‰å…ƒæ•°æ®éœ€è¦ä¿ç•™
            if self.excel_metadata:
                logger.info(f"ä¿ç•™åŸå§‹æ ¼å¼å’Œæ‰¹æ³¨...")
                # å…ˆç”¨pandaså†™å…¥åŸºç¡€æ•°æ®
                with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                    for sheet_name, df in all_results.items():
                        df.to_excel(writer, sheet_name=sheet_name, index=False)

                        # å¦‚æœæœ‰å…ƒæ•°æ®ï¼Œåº”ç”¨åˆ°å·¥ä½œè¡¨
                        if sheet_name in self.excel_metadata:
                            worksheet = writer.sheets[sheet_name]
                            metadata = self.excel_metadata[sheet_name]

                            # åº”ç”¨æ‰¹æ³¨å’Œé¢œè‰²
                            from openpyxl.comments import Comment
                            from openpyxl.styles import Font, PatternFill

                            for cell_address, cell_metadata in metadata.items():
                                try:
                                    cell = worksheet[cell_address]

                                    # æ·»åŠ æ‰¹æ³¨
                                    if cell_metadata.comment:
                                        comment = Comment(cell_metadata.comment, "Translation System")
                                        cell.comment = comment

                                    # è®¾ç½®å­—ä½“é¢œè‰²
                                    if cell_metadata.font_color:
                                        color_hex = cell_metadata.font_color.replace('#', '')
                                        cell.font = Font(
                                            color=color_hex,
                                            bold=cell_metadata.font_bold,
                                            italic=cell_metadata.font_italic
                                        )

                                    # è®¾ç½®å¡«å……è‰²
                                    if cell_metadata.fill_color:
                                        color_hex = cell_metadata.fill_color.replace('#', '')
                                        cell.fill = PatternFill(
                                            start_color=color_hex,
                                            end_color=color_hex,
                                            fill_type='solid'
                                        )
                                except Exception as e:
                                    logger.warning(f"åº”ç”¨å…ƒæ•°æ®å¤±è´¥ {cell_address}: {e}")
            else:
                # æ²¡æœ‰å…ƒæ•°æ®ï¼Œä½¿ç”¨æ™®é€šä¿å­˜
                with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                    for sheet_name, df in all_results.items():
                        df.to_excel(writer, sheet_name=sheet_name, index=False)

            logger.info(f"âœ… å¤šSheetç¿»è¯‘ç»“æœå·²ä¿å­˜: {output_path}")

            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            await self.project_manager.update_task_progress(
                db, task_id,
                status='completed'
            )

        except Exception as e:
            logger.error(f"ä¿å­˜å¤šSheetç»“æœå¤±è´¥: {e}")
            raise

    async def _save_and_complete_task(self, db: AsyncSession, task_id: str, df: pd.DataFrame, original_file_path: str):
        """ä¿å­˜ç»“æœå¹¶å®Œæˆä»»åŠ¡ï¼ˆå•Sheetå…¼å®¹ï¼‰"""
        try:
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å (åŸºäºDemoçš„å‘½åè§„åˆ™)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            base_name = original_file_path.rsplit('.', 1)[0]
            output_path = f"{base_name}_completed_{timestamp}.xlsx"

            # ä¿å­˜Excelæ–‡ä»¶
            df.to_excel(output_path, index=False)
            logger.info(f"ç¿»è¯‘ç»“æœå·²ä¿å­˜: {output_path}")

            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            await self.project_manager.update_task_progress(
                db, task_id,
                status='completed'
            )

        except Exception as e:
            logger.error(f"ä¿å­˜ç¿»è¯‘ç»“æœå¤±è´¥: {e}")
            raise

    def _check_direct_replace_strategy(self, batch_texts: List[str], matched_terms: Dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥ä½¿ç”¨ç›´æ¥æ›¿æ¢ç­–ç•¥ï¼ˆç®€å•æœ¯è¯­æ›¿æ¢ï¼Œä¸éœ€è¦LLMï¼‰"""
        if not matched_terms:
            return False

        # æ£€æŸ¥æ¯ä¸ªæ–‡æœ¬æ˜¯å¦åªåŒ…å«æœ¯è¯­ï¼ˆä¸å«å…¶ä»–éœ€è¦ç¿»è¯‘çš„å†…å®¹ï¼‰
        for text in batch_texts:
            # ç§»é™¤æ‰€æœ‰æœ¯è¯­åï¼Œå¦‚æœè¿˜æœ‰ä¸­æ–‡å­—ç¬¦ï¼Œåˆ™ä¸èƒ½ç›´æ¥æ›¿æ¢
            temp_text = text
            for term in matched_terms.keys():
                temp_text = temp_text.replace(term, '')

            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ä¸­æ–‡å­—ç¬¦ï¼ˆéœ€è¦LLMç¿»è¯‘ï¼‰
            if any('\u4e00' <= char <= '\u9fff' for char in temp_text):
                return False

        return True

    def _apply_direct_replacement(
        self,
        batch: List,
        matched_terms: Dict,
        target_languages: List[str]
    ) -> Dict:
        """ç›´æ¥åº”ç”¨æœ¯è¯­æ›¿æ¢ï¼Œè·³è¿‡LLMè°ƒç”¨"""
        batch_results = {}

        for task in batch:
            translated_text = task.source_text
            # æŒ‰ä¼˜å…ˆçº§æ’åºæœ¯è¯­ï¼Œä¼˜å…ˆæ›¿æ¢é•¿çš„æœ¯è¯­
            sorted_terms = sorted(
                matched_terms.items(),
                key=lambda x: (len(x[0]), x[1].priority),
                reverse=True
            )

            # åº”ç”¨æœ¯è¯­æ›¿æ¢
            for source, entry in sorted_terms:
                if task.target_language in entry.target:
                    translated_text = translated_text.replace(
                        source,
                        entry.target[task.target_language]
                    )

            batch_results[task.row_index] = {
                task.target_language: translated_text
            }

        logger.info(f"âœ¨ ä½¿ç”¨ç›´æ¥æ›¿æ¢ç­–ç•¥å¤„ç†{len(batch)}ä¸ªä»»åŠ¡ï¼ˆèŠ‚çœAPIè°ƒç”¨ï¼‰")
        return batch_results

    def _verify_terminology_usage(
        self,
        source_text: str,
        translated_text: str,
        matched_terms: Dict,
        target_language: str
    ) -> Dict[str, Any]:
        """éªŒè¯æœ¯è¯­æ˜¯å¦è¢«æ­£ç¡®ä½¿ç”¨"""
        verification_result = {
            'all_terms_used': True,
            'missing_terms': [],
            'incorrect_terms': [],
            'success_rate': 100.0
        }

        if not matched_terms:
            return verification_result

        total_terms = 0
        correct_terms = 0

        for source, entry in matched_terms.items():
            if source in source_text and target_language in entry.target:
                total_terms += 1
                expected_translation = entry.target[target_language]

                # æ£€æŸ¥è¯‘æ–‡ä¸­æ˜¯å¦åŒ…å«æœŸæœ›çš„æœ¯è¯­ç¿»è¯‘
                if expected_translation in translated_text:
                    correct_terms += 1
                else:
                    verification_result['missing_terms'].append({
                        'source': source,
                        'expected': expected_translation,
                        'found': False
                    })

        if total_terms > 0:
            verification_result['success_rate'] = (correct_terms / total_terms) * 100
            verification_result['all_terms_used'] = (correct_terms == total_terms)

        if verification_result['success_rate'] < 100:
            logger.warning(
                f"æœ¯è¯­ä½¿ç”¨éªŒè¯: æˆåŠŸç‡ {verification_result['success_rate']:.1f}%, "
                f"ç¼ºå¤±æœ¯è¯­: {len(verification_result['missing_terms'])}"
            )

        return verification_result

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.llm_instance and hasattr(self.llm_instance, 'close'):
            await self.llm_instance.close()
            logger.info("LLM instance closed")

        # æ¸…ç†ç®¡ç†å™¨ä¸­çš„æ‰€æœ‰å®ä¾‹
        if self.llm_manager and hasattr(self.llm_manager, '_llm_instances'):
            for profile, llm in self.llm_manager._llm_instances.items():
                if llm != self.llm_instance and hasattr(llm, 'close'):
                    await llm.close()
            logger.info("All LLM resources cleaned up")
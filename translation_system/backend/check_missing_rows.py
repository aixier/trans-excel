#!/usr/bin/env python3
"""
æ£€æŸ¥ç¼ºå¤±çš„è¡Œå’Œç¿»è¯‘ä»»åŠ¡
"""
import pandas as pd
import numpy as np
import openpyxl
from openpyxl import load_workbook
import re
import json
from datetime import datetime
import sys
import os

def detailed_row_analysis(original_file, result_file):
    """è¯¦ç»†åˆ†ææ¯ä¸€è¡Œçš„ç¿»è¯‘çŠ¶æ€"""
    print(f"\n{'='*80}")
    print("ğŸ” é€è¡Œç¿»è¯‘çŠ¶æ€åˆ†æ")
    print(f"{'='*80}")

    try:
        # åŠ è½½å·¥ä½œç°¿
        orig_wb = load_workbook(original_file, data_only=True)
        result_wb = load_workbook(result_file, data_only=True)

        all_missing_tasks = []

        for sheet_name in orig_wb.sheetnames:
            print(f"\nğŸ“‹ åˆ†æSheet: {sheet_name}")

            orig_ws = orig_wb[sheet_name]

            if sheet_name not in result_wb.sheetnames:
                print(f"âŒ ç»“æœæ–‡ä»¶ä¸­å®Œå…¨ç¼ºå°‘Sheet: {sheet_name}")
                continue

            result_ws = result_wb[sheet_name]

            print(f"   åŸå§‹: {orig_ws.max_row} è¡Œ x {orig_ws.max_column} åˆ—")
            print(f"   ç»“æœ: {result_ws.max_row} è¡Œ x {result_ws.max_column} åˆ—")

            # ç»Ÿè®¡å„ç§çŠ¶æ€
            original_texts = 0
            translated_rows = 0
            missing_rows = 0
            partial_translations = 0
            problematic_texts = []

            for row in range(1, orig_ws.max_row + 1):
                # æ£€æŸ¥Båˆ—ï¼ˆè‹±æ–‡åŸæ–‡ï¼‰
                orig_cell_b = orig_ws.cell(row=row, column=2)
                if orig_cell_b.value and isinstance(orig_cell_b.value, str) and orig_cell_b.value.strip():
                    original_texts += 1

                    # æ£€æŸ¥è¿™ä¸€è¡Œåœ¨ç»“æœæ–‡ä»¶ä¸­æ˜¯å¦å­˜åœ¨
                    if row > result_ws.max_row:
                        missing_rows += 1
                        all_missing_tasks.append({
                            'sheet': sheet_name,
                            'row': row,
                            'type': 'missing_row',
                            'original_text': orig_cell_b.value,
                            'text_length': len(orig_cell_b.value),
                            'issues': analyze_text_complexity(orig_cell_b.value)
                        })
                        continue

                    # æ£€æŸ¥ç¿»è¯‘çŠ¶æ€
                    row_translation_status = {
                        'Portuguese': False,  # Cåˆ—
                        'Thai': False,        # Dåˆ—
                        'Indonesian': False   # Eåˆ—
                    }

                    # æ£€æŸ¥Cåˆ—ï¼ˆè‘¡è„ç‰™è¯­ï¼‰
                    if result_ws.max_column >= 3:
                        result_cell_c = result_ws.cell(row=row, column=3)
                        if result_cell_c.value and str(result_cell_c.value).strip():
                            row_translation_status['Portuguese'] = True

                    # æ£€æŸ¥Dåˆ—ï¼ˆæ³°è¯­ï¼‰
                    if result_ws.max_column >= 4:
                        result_cell_d = result_ws.cell(row=row, column=4)
                        if result_cell_d.value and str(result_cell_d.value).strip():
                            row_translation_status['Thai'] = True

                    # æ£€æŸ¥Eåˆ—ï¼ˆå°å°¼è¯­ï¼‰
                    if result_ws.max_column >= 5:
                        result_cell_e = result_ws.cell(row=row, column=5)
                        if result_cell_e.value and str(result_cell_e.value).strip():
                            row_translation_status['Indonesian'] = True

                    # ç»Ÿè®¡ç¿»è¯‘çŠ¶æ€
                    translations_completed = sum(row_translation_status.values())

                    if translations_completed == 3:
                        translated_rows += 1
                    elif translations_completed > 0:
                        partial_translations += 1
                        # è®°å½•éƒ¨åˆ†ç¿»è¯‘çš„ä»»åŠ¡
                        for lang, completed in row_translation_status.items():
                            if not completed:
                                all_missing_tasks.append({
                                    'sheet': sheet_name,
                                    'row': row,
                                    'type': 'missing_translation',
                                    'language': lang,
                                    'original_text': orig_cell_b.value,
                                    'text_length': len(orig_cell_b.value),
                                    'issues': analyze_text_complexity(orig_cell_b.value)
                                })
                    else:
                        # å®Œå…¨æ²¡æœ‰ç¿»è¯‘
                        for lang in ['Portuguese', 'Thai', 'Indonesian']:
                            all_missing_tasks.append({
                                'sheet': sheet_name,
                                'row': row,
                                'type': 'no_translation',
                                'language': lang,
                                'original_text': orig_cell_b.value,
                                'text_length': len(orig_cell_b.value),
                                'issues': analyze_text_complexity(orig_cell_b.value)
                            })

            print(f"   ğŸ“Š ç»Ÿè®¡:")
            print(f"      åŸå§‹æ–‡æœ¬æ•°: {original_texts}")
            print(f"      å®Œå…¨ç¿»è¯‘è¡Œ: {translated_rows}")
            print(f"      éƒ¨åˆ†ç¿»è¯‘è¡Œ: {partial_translations}")
            print(f"      ç¼ºå¤±è¡Œæ•°: {missing_rows}")
            print(f"      ç¿»è¯‘å®Œæˆç‡: {(translated_rows/original_texts*100 if original_texts > 0 else 0):.1f}%")

        # åˆ†æç¼ºå¤±ä»»åŠ¡
        print(f"\nğŸ“ˆ ç¼ºå¤±ä»»åŠ¡åˆ†æ:")
        print(f"   æ€»ç¼ºå¤±ä»»åŠ¡: {len(all_missing_tasks)}")

        # æŒ‰ç±»å‹åˆ†ç»„
        by_type = {}
        for task in all_missing_tasks:
            task_type = task['type']
            if task_type not in by_type:
                by_type[task_type] = []
            by_type[task_type].append(task)

        for task_type, tasks in by_type.items():
            print(f"   {task_type}: {len(tasks)} ä¸ª")

        # æŒ‰è¯­è¨€åˆ†ç»„
        by_language = {}
        for task in all_missing_tasks:
            if 'language' in task:
                lang = task['language']
                if lang not in by_language:
                    by_language[lang] = []
                by_language[lang].append(task)

        print(f"\nğŸ“Š æŒ‰è¯­è¨€åˆ†ç»„:")
        for lang, tasks in by_language.items():
            print(f"   {lang}: {len(tasks)} ä¸ªä»»åŠ¡")

        return all_missing_tasks

    except Exception as e:
        print(f"âŒ åˆ†ææ—¶å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
        return []

def analyze_text_complexity(text):
    """åˆ†ææ–‡æœ¬å¤æ‚åº¦"""
    issues = []

    if len(text) > 300:
        issues.append("é•¿æ–‡æœ¬")
    if len(text) > 600:
        issues.append("è¶…é•¿æ–‡æœ¬")

    # ç‰¹æ®Šå­—ç¬¦
    special_chars = re.findall(r'[<>]', text)
    if len(special_chars) > 3:
        issues.append("HTMLæ ‡ç­¾")

    if '\n' in text:
        issues.append("æ¢è¡Œç¬¦")
    if '\t' in text:
        issues.append("åˆ¶è¡¨ç¬¦")
    if '%s' in text or '%d' in text:
        issues.append("å ä½ç¬¦")
    if re.search(r'\d+\.', text):
        issues.append("ç¼–å·åˆ—è¡¨")

    return issues

def find_hardest_tasks(missing_tasks):
    """æ‰¾å‡ºæœ€å›°éš¾çš„ä»»åŠ¡"""
    print(f"\n{'='*80}")
    print("ğŸ”¥ æœ€å›°éš¾ä»»åŠ¡è¯†åˆ«")
    print(f"{'='*80}")

    # è®¡ç®—å›°éš¾åº¦åˆ†æ•°
    for task in missing_tasks:
        difficulty_score = 0

        # æ–‡æœ¬é•¿åº¦å¾—åˆ†
        length = task['text_length']
        if length > 600:
            difficulty_score += 4
        elif length > 300:
            difficulty_score += 2
        elif length > 100:
            difficulty_score += 1

        # é—®é¢˜ç±»å‹å¾—åˆ†
        for issue in task['issues']:
            if issue == "è¶…é•¿æ–‡æœ¬":
                difficulty_score += 3
            elif issue == "HTMLæ ‡ç­¾":
                difficulty_score += 2
            elif issue in ["æ¢è¡Œç¬¦", "ç¼–å·åˆ—è¡¨"]:
                difficulty_score += 2
            else:
                difficulty_score += 1

        task['difficulty_score'] = difficulty_score

    # æ’åºæ‰¾å‡ºæœ€å›°éš¾çš„
    hardest_tasks = sorted(missing_tasks,
                          key=lambda x: x['difficulty_score'],
                          reverse=True)

    print(f"ğŸ¯ æœ€å›°éš¾çš„6ä¸ªä»»åŠ¡:")
    for i, task in enumerate(hardest_tasks[:6]):
        print(f"\n   {i+1}. Sheet: {task['sheet']}, è¡Œ: {task['row']}")
        print(f"      è¯­è¨€: {task.get('language', 'All')}")
        print(f"      ç±»å‹: {task['type']}")
        print(f"      å›°éš¾åº¦: {task['difficulty_score']} åˆ†")
        print(f"      æ–‡æœ¬é•¿åº¦: {task['text_length']} å­—ç¬¦")
        print(f"      é—®é¢˜: {', '.join(task['issues']) if task['issues'] else 'æ— ç‰¹æ®Šé—®é¢˜'}")
        preview = task['original_text'][:80] + "..." if len(task['original_text']) > 80 else task['original_text']
        print(f"      é¢„è§ˆ: {preview}")

    return hardest_tasks[:6]

def main():
    """ä¸»å‡½æ•°"""
    print("Excelç¿»è¯‘ç¼ºå¤±ä»»åŠ¡è¯¦ç»†åˆ†æ")
    print(f"åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # æ–‡ä»¶è·¯å¾„
    original_file = "/mnt/d/work/trans_excel/stuck_original.xlsx"
    result_file = "/mnt/d/work/trans_excel/stuck_result.xlsx"

    # è¯¦ç»†åˆ†æ
    missing_tasks = detailed_row_analysis(original_file, result_file)

    if missing_tasks:
        # æ‰¾å‡ºæœ€å›°éš¾çš„ä»»åŠ¡
        hardest_tasks = find_hardest_tasks(missing_tasks)

        print(f"\n{'='*80}")
        print("ğŸ’¡ è§£å†³å»ºè®®")
        print(f"{'='*80}")
        print("1. ä¼˜å…ˆå¤„ç†å›°éš¾åº¦æœ€é«˜çš„6ä¸ªä»»åŠ¡")
        print("2. å¯¹è¶…é•¿æ–‡æœ¬è¿›è¡Œåˆ†æ®µå¤„ç†")
        print("3. é¢„å¤„ç†HTMLæ ‡ç­¾å’Œç‰¹æ®Šå­—ç¬¦")
        print("4. å¢åŠ æ•°æ®åº“è¿æ¥çš„é‡è¯•æœºåˆ¶")
        print("5. å®ç°ç¿»è¯‘è¿›åº¦çš„æ–­ç‚¹ç»­ä¼ ")
    else:
        print("âœ… æ‰€æœ‰ç¿»è¯‘ä»»åŠ¡å·²å®Œæˆ")

    print(f"\n{'='*80}")
    print("âœ… åˆ†æå®Œæˆ")
    print(f"{'='*80}")

if __name__ == "__main__":
    main()
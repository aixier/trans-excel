# Persistence Service - 架构设计文档

## 1. 服务概述

Persistence Service 是一个独立的数据持久化服务，负责将翻译系统的运行数据批量写入 MySQL 数据库。

### 设计目标

- **完全解耦**：与主业务系统通过 HTTP API 通信，互不依赖
- **批量高效**：批量写入数据库，减少数据库压力
- **简单可靠**：接受数据丢失（最多一批），换取架构简单性
- **异步非阻塞**：API 调用立即返回，不阻塞业务逻辑

### 数据丢失容忍度

- **可接受**：服务崩溃时丢失内存中的一批数据（最多 30 秒或 1000 条）
- **不可接受**：数据不一致、重复写入、损坏

## 2. 核心架构

```
┌─────────────────────────────────────────────────────────────┐
│                    Backend V2 (主业务系统)                    │
│                                                               │
│  ┌─────────────────────────────────────────────────────┐    │
│  │  TaskPersister (客户端)                              │    │
│  │  - 收集需要持久化的数据                              │    │
│  │  - 批量发送到 Persistence Service                    │    │
│  │  - Fire-and-Forget (不等待响应)                      │    │
│  └─────────────────────────────────────────────────────┘    │
│                          │                                    │
└──────────────────────────┼────────────────────────────────────┘
                           │ HTTP POST
                           │ (异步，不等待)
┌──────────────────────────▼────────────────────────────────────┐
│              Persistence Service (独立服务)                    │
│                                                                │
│  ┌────────────────────┐         ┌──────────────────────┐     │
│  │   Batch API        │         │   Buffer Manager     │     │
│  │  /api/v1/sessions  │────────▶│  - 内存缓冲区        │     │
│  │  /api/v1/tasks     │         │  - 批量累积          │     │
│  │  /api/v1/flush     │         │  - 定期刷新          │     │
│  └────────────────────┘         └──────────────────────┘     │
│                                           │                    │
│                                           │ 批量写入           │
│                                           ▼                    │
│                                  ┌─────────────────┐          │
│                                  │  Database Writer│          │
│                                  │  - 批量 upsert  │          │
│                                  │  - 幂等性保证   │          │
│                                  └─────────────────┘          │
│                                           │                    │
└───────────────────────────────────────────┼────────────────────┘
                                            │
                                            ▼
                                    ┌──────────────┐
                                    │    MySQL     │
                                    │   Database   │
                                    └──────────────┘
```

## 3. 核心组件

### 3.1 Batch API (api/)

HTTP API 端点，接收批量数据请求

**职责：**
- 接收客户端的批量数据
- 验证数据格式
- 添加到缓冲区
- 立即返回（不等待数据库写入）

**端点设计：**
```
POST /api/v1/persistence/sessions/batch  # 批量创建/更新会话
POST /api/v1/persistence/tasks/batch     # 批量创建/更新任务
POST /api/v1/persistence/flush           # 强制刷新缓冲区
GET  /api/v1/persistence/stats           # 获取缓冲区统计
GET  /health                              # 健康检查
```

### 3.2 Buffer Manager (services/)

内存缓冲区管理器

**职责：**
- 管理两个内存缓冲区（sessions, tasks）
- 检查刷新条件（数量阈值或时间间隔）
- 定期触发批量写入

**刷新条件：**
- 缓冲区达到 `max_buffer_size`（默认 1000 条）
- 距离上次刷新超过 `flush_interval`（默认 30 秒）

**数据丢失点：**
- 如果服务崩溃，内存中的缓冲区数据会丢失
- 最多丢失：1000 条或 30 秒的数据

### 3.3 Database Writer (database/)

数据库写入器

**职责：**
- 批量写入数据库（使用 upsert 语句）
- 保证幂等性（重复调用不会产生重复数据）
- 处理数据库连接失败

**写入策略：**
- 使用 `INSERT ... ON DUPLICATE KEY UPDATE`（幂等）
- 批量操作（一次写入多条）
- 失败不重试（接受数据丢失）

### 3.4 Models (models/)

数据模型定义

**职责：**
- 定义 API 请求/响应模型
- 定义数据库表结构映射

### 3.5 Config (config/)

配置管理

**配置项：**
```python
# 缓冲区配置
MAX_BUFFER_SIZE = 1000          # 最大缓冲条数
FLUSH_INTERVAL = 30             # 刷新间隔（秒）

# 数据库配置
DB_HOST = "localhost"
DB_PORT = 3306
DB_USER = "root"
DB_PASSWORD = ""
DB_DATABASE = "ai_terminal"
DB_POOL_SIZE = 10

# 服务配置
SERVICE_HOST = "0.0.0.0"
SERVICE_PORT = 8001
```

## 4. 数据流

### 4.1 正常流程

```
1. 主业务系统产生数据（任务完成、状态更新等）
   ↓
2. PersistenceClient 累积数据到本地缓冲区
   ↓
3. 达到批次大小（如 100 条），发送 HTTP POST 到 Persistence Service
   ↓
4. Persistence Service 立即返回 {"status": "accepted"}
   ↓
5. Buffer Manager 将数据添加到内存缓冲区
   ↓
6. 达到刷新条件（1000 条或 30 秒）
   ↓
7. Database Writer 批量写入 MySQL
   ↓
8. 成功后清空缓冲区
```

### 4.2 异常流程

**场景 1：Persistence Service 崩溃**
```
1. 主业务系统调用 API 超时或失败
   ↓
2. 客户端记录警告日志，丢弃该批数据（不重试）
   ↓
3. 内存中的缓冲区数据丢失（最多 1000 条或 30 秒）
   ↓
4. 服务重启后，从下一批数据开始重新接收
```

**场景 2：数据库写入失败**
```
1. Database Writer 批量写入失败（连接断开、超时等）
   ↓
2. 记录错误日志
   ↓
3. 丢弃该批数据（不重试）
   ↓
4. 下次刷新时使用新数据
```

**场景 3：客户端网络超时**
```
1. 客户端发送请求后 2 秒超时
   ↓
2. 客户端记录警告，丢弃数据
   ↓
3. 服务端可能已接收（继续处理）或未接收（数据丢失）
   ↓
4. 接受该不确定性
```

## 5. 性能指标

### 预期性能

| 指标                | 目标值            |
|---------------------|-------------------|
| API 响应时间        | < 10ms            |
| 批量写入时间        | < 1s (1000 条)    |
| 数据库压力          | 降低 95%+         |
| 最大数据丢失        | 30 秒 或 1000 条  |

### 吞吐量估算

假设：
- 每秒产生 50 个任务更新
- 缓冲区大小 1000 条
- 刷新间隔 30 秒

则：
- 30 秒内累积：50 * 30 = 1500 条 > 1000，触发刷新
- 实际刷新频率：约 20 秒一次（1000 条）
- 数据库写入频率：3 次/分钟
- 对比原方案（每条立即写入）：降低数据库操作 99.5%

## 6. 优缺点分析

### 优点

1. **架构解耦**：主业务系统完全不依赖持久化逻辑
2. **性能优异**：批量写入大幅减少数据库压力
3. **简单可靠**：无复杂状态机、消息队列、重试逻辑
4. **易于扩展**：可独立扩展、升级、重启
5. **容错清晰**：数据丢失边界明确

### 缺点

1. **数据丢失**：服务崩溃会丢失最多 1000 条或 30 秒数据
2. **延迟写入**：数据不是实时写入数据库（最多延迟 30 秒）
3. **最终一致**：主业务系统内存与数据库存在短暂不一致

### 适用场景

✅ **适合：**
- 可容忍短时间数据丢失的场景（如进度跟踪、统计数据）
- 高频写入场景（如任务状态更新）
- 需要降低数据库压力的场景

❌ **不适合：**
- 金融交易等零容忍数据丢失场景
- 需要实时数据一致性的场景
- 需要立即读取刚写入数据的场景

## 7. 与现有系统对比

### 原方案（Backend V2 直接持久化）

```
业务逻辑 → TaskPersister → MySQLConnector → MySQL
          (每 30 秒)        (每条一次写入)
```

**问题：**
- 耦合度高：TaskPersister 依赖 MySQLConnector
- 事务复杂：Session 和 Task 需要两次写入
- 竞态条件：DataFrame 并发访问风险
- 数据库压力大：频繁的小事务

### 新方案（独立持久化服务）

```
业务逻辑 → PersistenceClient → [HTTP] → Persistence Service → MySQL
          (累积 100 条)                   (批量 1000 条)
```

**改进：**
- 完全解耦：通过 HTTP API 通信
- 批量高效：1000 条一次写入
- 异步非阻塞：Fire-and-Forget
- 职责清晰：各服务独立演进

## 8. 演进路线

### Phase 1: 原型验证（当前阶段）
- 创建独立服务目录结构
- 实现基本 API 和缓冲管理
- 单机部署验证

### Phase 2: 生产就绪
- 添加监控指标（Prometheus）
- 添加健康检查和优雅关闭
- 完善错误处理和日志

### Phase 3: 高可用
- 多实例部署（无状态）
- 负载均衡（Nginx/Traefik）
- 数据库连接池优化

### Phase 4: 可观测性
- 集成链路追踪（Jaeger）
- 添加业务指标仪表盘（Grafana）
- 告警规则配置

## 9. 部署方案

### 开发环境
```bash
# 直接运行
cd persistence_service
python main.py  # 启动在 8001 端口
```

### 生产环境（未来）
```bash
# 使用 systemd
sudo systemctl start persistence-service
sudo systemctl enable persistence-service
```

## 10. 总结

Persistence Service 通过**批量处理**和**容忍数据丢失**的设计理念，实现了：
- 架构简单（无消息队列、无复杂重试）
- 性能优异（数据库压力降低 99%+）
- 完全解耦（独立服务，HTTP 通信）

代价是：
- 最多丢失 30 秒或 1000 条数据（可接受）
- 数据延迟 30 秒写入（可接受）

**这是一个针对翻译系统特点量身定制的实用方案。**